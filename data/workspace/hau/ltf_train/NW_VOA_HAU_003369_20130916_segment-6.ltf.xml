<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
<DOC id="NW_VOA_HAU_003369_20130916">
<TEXT>
<SEG end_char="1159" id="segment-6" start_char="1001">
<ORIGINAL_TEXT>Sai dai suka ce, sakamakon binciken ya nuna yanayin mutanen da aka gudanar da binciken a kansu ne kawai ba za a iya sanin ko haka zata faru ga dukan jamaÊ¼a ba.</ORIGINAL_TEXT>
<TOKEN end_char="1003" id="token-6-0" morph="none" pos="word" start_char="1001">Sai</TOKEN>
<TOKEN end_char="1007" id="token-6-1" morph="none" pos="word" start_char="1005">dai</TOKEN>
<TOKEN end_char="1012" id="token-6-2" morph="none" pos="word" start_char="1009">suka</TOKEN>
<TOKEN end_char="1015" id="token-6-3" morph="none" pos="word" start_char="1014">ce</TOKEN>
<TOKEN end_char="1016" id="token-6-4" morph="none" pos="punct" start_char="1016">,</TOKEN>
<TOKEN end_char="1026" id="token-6-5" morph="none" pos="word" start_char="1018">sakamakon</TOKEN>
<TOKEN end_char="1035" id="token-6-6" morph="none" pos="word" start_char="1028">binciken</TOKEN>
<TOKEN end_char="1038" id="token-6-7" morph="none" pos="word" start_char="1037">ya</TOKEN>
<TOKEN end_char="1043" id="token-6-8" morph="none" pos="word" start_char="1040">nuna</TOKEN>
<TOKEN end_char="1051" id="token-6-9" morph="none" pos="word" start_char="1045">yanayin</TOKEN>
<TOKEN end_char="1059" id="token-6-10" morph="none" pos="word" start_char="1053">mutanen</TOKEN>
<TOKEN end_char="1062" id="token-6-11" morph="none" pos="word" start_char="1061">da</TOKEN>
<TOKEN end_char="1066" id="token-6-12" morph="none" pos="word" start_char="1064">aka</TOKEN>
<TOKEN end_char="1074" id="token-6-13" morph="none" pos="word" start_char="1068">gudanar</TOKEN>
<TOKEN end_char="1077" id="token-6-14" morph="none" pos="word" start_char="1076">da</TOKEN>
<TOKEN end_char="1086" id="token-6-15" morph="none" pos="word" start_char="1079">binciken</TOKEN>
<TOKEN end_char="1088" id="token-6-16" morph="none" pos="word" start_char="1088">a</TOKEN>
<TOKEN end_char="1094" id="token-6-17" morph="none" pos="word" start_char="1090">kansu</TOKEN>
<TOKEN end_char="1097" id="token-6-18" morph="none" pos="word" start_char="1096">ne</TOKEN>
<TOKEN end_char="1103" id="token-6-19" morph="none" pos="word" start_char="1099">kawai</TOKEN>
<TOKEN end_char="1106" id="token-6-20" morph="none" pos="word" start_char="1105">ba</TOKEN>
<TOKEN end_char="1109" id="token-6-21" morph="none" pos="word" start_char="1108">za</TOKEN>
<TOKEN end_char="1111" id="token-6-22" morph="none" pos="word" start_char="1111">a</TOKEN>
<TOKEN end_char="1115" id="token-6-23" morph="none" pos="word" start_char="1113">iya</TOKEN>
<TOKEN end_char="1121" id="token-6-24" morph="none" pos="word" start_char="1117">sanin</TOKEN>
<TOKEN end_char="1124" id="token-6-25" morph="none" pos="word" start_char="1123">ko</TOKEN>
<TOKEN end_char="1129" id="token-6-26" morph="none" pos="word" start_char="1126">haka</TOKEN>
<TOKEN end_char="1134" id="token-6-27" morph="none" pos="word" start_char="1131">zata</TOKEN>
<TOKEN end_char="1139" id="token-6-28" morph="none" pos="word" start_char="1136">faru</TOKEN>
<TOKEN end_char="1142" id="token-6-29" morph="none" pos="word" start_char="1141">ga</TOKEN>
<TOKEN end_char="1148" id="token-6-30" morph="none" pos="word" start_char="1144">dukan</TOKEN>
<TOKEN end_char="1155" id="token-6-31" morph="none" pos="word" start_char="1150">jamaÊ¼a</TOKEN>
<TOKEN end_char="1158" id="token-6-32" morph="none" pos="word" start_char="1157">ba</TOKEN>
<TOKEN end_char="1159" id="token-6-33" morph="none" pos="punct" start_char="1159">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>