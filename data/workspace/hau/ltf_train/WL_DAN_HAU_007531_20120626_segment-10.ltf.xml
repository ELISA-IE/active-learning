<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
<DOC id="WL_DAN_HAU_007531_20120626">
<TEXT>
<SEG end_char="2996" id="segment-10" start_char="2810">
<ORIGINAL_TEXT>A karshe ba abin da zance sai godiya ga 始yan uwa da suka taya mu da addu始a, musamman wadanda suka yi ta kirana a waya suna tambayar lafiyata, Allah ya saka da alheri, ya kuma bar zumunci.</ORIGINAL_TEXT>
<TOKEN end_char="2810" id="token-10-0" morph="none" pos="word" start_char="2810">A</TOKEN>
<TOKEN end_char="2817" id="token-10-1" morph="none" pos="word" start_char="2812">karshe</TOKEN>
<TOKEN end_char="2820" id="token-10-2" morph="none" pos="word" start_char="2819">ba</TOKEN>
<TOKEN end_char="2825" id="token-10-3" morph="none" pos="word" start_char="2822">abin</TOKEN>
<TOKEN end_char="2828" id="token-10-4" morph="none" pos="word" start_char="2827">da</TOKEN>
<TOKEN end_char="2834" id="token-10-5" morph="none" pos="word" start_char="2830">zance</TOKEN>
<TOKEN end_char="2838" id="token-10-6" morph="none" pos="word" start_char="2836">sai</TOKEN>
<TOKEN end_char="2845" id="token-10-7" morph="none" pos="word" start_char="2840">godiya</TOKEN>
<TOKEN end_char="2848" id="token-10-8" morph="none" pos="word" start_char="2847">ga</TOKEN>
<TOKEN end_char="2853" id="token-10-9" morph="none" pos="word" start_char="2850">始yan</TOKEN>
<TOKEN end_char="2857" id="token-10-10" morph="none" pos="word" start_char="2855">uwa</TOKEN>
<TOKEN end_char="2860" id="token-10-11" morph="none" pos="word" start_char="2859">da</TOKEN>
<TOKEN end_char="2865" id="token-10-12" morph="none" pos="word" start_char="2862">suka</TOKEN>
<TOKEN end_char="2870" id="token-10-13" morph="none" pos="word" start_char="2867">taya</TOKEN>
<TOKEN end_char="2873" id="token-10-14" morph="none" pos="word" start_char="2872">mu</TOKEN>
<TOKEN end_char="2876" id="token-10-15" morph="none" pos="word" start_char="2875">da</TOKEN>
<TOKEN end_char="2883" id="token-10-16" morph="none" pos="word" start_char="2878">addu始a</TOKEN>
<TOKEN end_char="2884" id="token-10-17" morph="none" pos="punct" start_char="2884">,</TOKEN>
<TOKEN end_char="2893" id="token-10-18" morph="none" pos="word" start_char="2886">musamman</TOKEN>
<TOKEN end_char="2901" id="token-10-19" morph="none" pos="word" start_char="2895">wadanda</TOKEN>
<TOKEN end_char="2906" id="token-10-20" morph="none" pos="word" start_char="2903">suka</TOKEN>
<TOKEN end_char="2909" id="token-10-21" morph="none" pos="word" start_char="2908">yi</TOKEN>
<TOKEN end_char="2912" id="token-10-22" morph="none" pos="word" start_char="2911">ta</TOKEN>
<TOKEN end_char="2919" id="token-10-23" morph="none" pos="word" start_char="2914">kirana</TOKEN>
<TOKEN end_char="2921" id="token-10-24" morph="none" pos="word" start_char="2921">a</TOKEN>
<TOKEN end_char="2926" id="token-10-25" morph="none" pos="word" start_char="2923">waya</TOKEN>
<TOKEN end_char="2931" id="token-10-26" morph="none" pos="word" start_char="2928">suna</TOKEN>
<TOKEN end_char="2940" id="token-10-27" morph="none" pos="word" start_char="2933">tambayar</TOKEN>
<TOKEN end_char="2949" id="token-10-28" morph="none" pos="word" start_char="2942">lafiyata</TOKEN>
<TOKEN end_char="2950" id="token-10-29" morph="none" pos="punct" start_char="2950">,</TOKEN>
<TOKEN end_char="2956" id="token-10-30" morph="none" pos="word" start_char="2952">Allah</TOKEN>
<TOKEN end_char="2959" id="token-10-31" morph="none" pos="word" start_char="2958">ya</TOKEN>
<TOKEN end_char="2964" id="token-10-32" morph="none" pos="word" start_char="2961">saka</TOKEN>
<TOKEN end_char="2967" id="token-10-33" morph="none" pos="word" start_char="2966">da</TOKEN>
<TOKEN end_char="2974" id="token-10-34" morph="none" pos="word" start_char="2969">alheri</TOKEN>
<TOKEN end_char="2975" id="token-10-35" morph="none" pos="punct" start_char="2975">,</TOKEN>
<TOKEN end_char="2978" id="token-10-36" morph="none" pos="word" start_char="2977">ya</TOKEN>
<TOKEN end_char="2983" id="token-10-37" morph="none" pos="word" start_char="2980">kuma</TOKEN>
<TOKEN end_char="2987" id="token-10-38" morph="none" pos="word" start_char="2985">bar</TOKEN>
<TOKEN end_char="2995" id="token-10-39" morph="none" pos="word" start_char="2989">zumunci</TOKEN>
<TOKEN end_char="2996" id="token-10-40" morph="none" pos="punct" start_char="2996">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>