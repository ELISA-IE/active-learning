<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
<DOC id="NW_VOA_HAU_005745_20141019">
<TEXT>
<SEG end_char="575" id="segment-3" start_char="463">
<ORIGINAL_TEXT>Goldring yace kasashen da suka kasa bada tallafi domin yaki d a cutar Ebola, suna kasar taimakawa hasarar rayuka.</ORIGINAL_TEXT>
<TOKEN end_char="470" id="token-3-0" morph="none" pos="word" start_char="463">Goldring</TOKEN>
<TOKEN end_char="475" id="token-3-1" morph="none" pos="word" start_char="472">yace</TOKEN>
<TOKEN end_char="484" id="token-3-2" morph="none" pos="word" start_char="477">kasashen</TOKEN>
<TOKEN end_char="487" id="token-3-3" morph="none" pos="word" start_char="486">da</TOKEN>
<TOKEN end_char="492" id="token-3-4" morph="none" pos="word" start_char="489">suka</TOKEN>
<TOKEN end_char="497" id="token-3-5" morph="none" pos="word" start_char="494">kasa</TOKEN>
<TOKEN end_char="502" id="token-3-6" morph="none" pos="word" start_char="499">bada</TOKEN>
<TOKEN end_char="510" id="token-3-7" morph="none" pos="word" start_char="504">tallafi</TOKEN>
<TOKEN end_char="516" id="token-3-8" morph="none" pos="word" start_char="512">domin</TOKEN>
<TOKEN end_char="521" id="token-3-9" morph="none" pos="word" start_char="518">yaki</TOKEN>
<TOKEN end_char="523" id="token-3-10" morph="none" pos="word" start_char="523">d</TOKEN>
<TOKEN end_char="525" id="token-3-11" morph="none" pos="word" start_char="525">a</TOKEN>
<TOKEN end_char="531" id="token-3-12" morph="none" pos="word" start_char="527">cutar</TOKEN>
<TOKEN end_char="537" id="token-3-13" morph="none" pos="word" start_char="533">Ebola</TOKEN>
<TOKEN end_char="538" id="token-3-14" morph="none" pos="punct" start_char="538">,</TOKEN>
<TOKEN end_char="543" id="token-3-15" morph="none" pos="word" start_char="540">suna</TOKEN>
<TOKEN end_char="549" id="token-3-16" morph="none" pos="word" start_char="545">kasar</TOKEN>
<TOKEN end_char="559" id="token-3-17" morph="none" pos="word" start_char="551">taimakawa</TOKEN>
<TOKEN end_char="567" id="token-3-18" morph="none" pos="word" start_char="561">hasarar</TOKEN>
<TOKEN end_char="574" id="token-3-19" morph="none" pos="word" start_char="569">rayuka</TOKEN>
<TOKEN end_char="575" id="token-3-20" morph="none" pos="punct" start_char="575">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>