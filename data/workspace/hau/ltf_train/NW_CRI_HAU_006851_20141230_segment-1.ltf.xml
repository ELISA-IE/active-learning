<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
<DOC id="NW_CRI_HAU_006851_20141230">
<TEXT>
<SEG end_char="412" id="segment-1" start_char="216">
<ORIGINAL_TEXT>A cewar kakakin tawagar, hare-haren irin wadanda ake gani a yanzu haka, ba za su warware matsalar da ake fuskanta ba, illa dai kawai sake rura wutar gaba, da kara tabarbarewar yanayin tsaron kasar.</ORIGINAL_TEXT>
<TOKEN end_char="216" id="token-1-0" morph="none" pos="word" start_char="216">A</TOKEN>
<TOKEN end_char="222" id="token-1-1" morph="none" pos="word" start_char="218">cewar</TOKEN>
<TOKEN end_char="230" id="token-1-2" morph="none" pos="word" start_char="224">kakakin</TOKEN>
<TOKEN end_char="238" id="token-1-3" morph="none" pos="word" start_char="232">tawagar</TOKEN>
<TOKEN end_char="239" id="token-1-4" morph="none" pos="punct" start_char="239">,</TOKEN>
<TOKEN end_char="244" id="token-1-5" morph="none" pos="word" start_char="241">hare</TOKEN>
<TOKEN end_char="245" id="token-1-6" morph="none" pos="punct" start_char="245">-</TOKEN>
<TOKEN end_char="250" id="token-1-7" morph="none" pos="word" start_char="246">haren</TOKEN>
<TOKEN end_char="255" id="token-1-8" morph="none" pos="word" start_char="252">irin</TOKEN>
<TOKEN end_char="263" id="token-1-9" morph="none" pos="word" start_char="257">wadanda</TOKEN>
<TOKEN end_char="267" id="token-1-10" morph="none" pos="word" start_char="265">ake</TOKEN>
<TOKEN end_char="272" id="token-1-11" morph="none" pos="word" start_char="269">gani</TOKEN>
<TOKEN end_char="274" id="token-1-12" morph="none" pos="word" start_char="274">a</TOKEN>
<TOKEN end_char="280" id="token-1-13" morph="none" pos="word" start_char="276">yanzu</TOKEN>
<TOKEN end_char="285" id="token-1-14" morph="none" pos="word" start_char="282">haka</TOKEN>
<TOKEN end_char="286" id="token-1-15" morph="none" pos="punct" start_char="286">,</TOKEN>
<TOKEN end_char="289" id="token-1-16" morph="none" pos="word" start_char="288">ba</TOKEN>
<TOKEN end_char="292" id="token-1-17" morph="none" pos="word" start_char="291">za</TOKEN>
<TOKEN end_char="295" id="token-1-18" morph="none" pos="word" start_char="294">su</TOKEN>
<TOKEN end_char="303" id="token-1-19" morph="none" pos="word" start_char="297">warware</TOKEN>
<TOKEN end_char="312" id="token-1-20" morph="none" pos="word" start_char="305">matsalar</TOKEN>
<TOKEN end_char="315" id="token-1-21" morph="none" pos="word" start_char="314">da</TOKEN>
<TOKEN end_char="319" id="token-1-22" morph="none" pos="word" start_char="317">ake</TOKEN>
<TOKEN end_char="328" id="token-1-23" morph="none" pos="word" start_char="321">fuskanta</TOKEN>
<TOKEN end_char="331" id="token-1-24" morph="none" pos="word" start_char="330">ba</TOKEN>
<TOKEN end_char="332" id="token-1-25" morph="none" pos="punct" start_char="332">,</TOKEN>
<TOKEN end_char="337" id="token-1-26" morph="none" pos="word" start_char="334">illa</TOKEN>
<TOKEN end_char="341" id="token-1-27" morph="none" pos="word" start_char="339">dai</TOKEN>
<TOKEN end_char="347" id="token-1-28" morph="none" pos="word" start_char="343">kawai</TOKEN>
<TOKEN end_char="352" id="token-1-29" morph="none" pos="word" start_char="349">sake</TOKEN>
<TOKEN end_char="357" id="token-1-30" morph="none" pos="word" start_char="354">rura</TOKEN>
<TOKEN end_char="363" id="token-1-31" morph="none" pos="word" start_char="359">wutar</TOKEN>
<TOKEN end_char="368" id="token-1-32" morph="none" pos="word" start_char="365">gaba</TOKEN>
<TOKEN end_char="369" id="token-1-33" morph="none" pos="punct" start_char="369">,</TOKEN>
<TOKEN end_char="372" id="token-1-34" morph="none" pos="word" start_char="371">da</TOKEN>
<TOKEN end_char="377" id="token-1-35" morph="none" pos="word" start_char="374">kara</TOKEN>
<TOKEN end_char="390" id="token-1-36" morph="none" pos="word" start_char="379">tabarbarewar</TOKEN>
<TOKEN end_char="398" id="token-1-37" morph="none" pos="word" start_char="392">yanayin</TOKEN>
<TOKEN end_char="405" id="token-1-38" morph="none" pos="word" start_char="400">tsaron</TOKEN>
<TOKEN end_char="411" id="token-1-39" morph="none" pos="word" start_char="407">kasar</TOKEN>
<TOKEN end_char="412" id="token-1-40" morph="none" pos="punct" start_char="412">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>