<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
<DOC id="NW_VOA_HAU_005468_20140902">
<TEXT>
<SEG end_char="389" id="segment-3" start_char="261">
<ORIGINAL_TEXT>Kamar yadda aka sani cutar ta shigo ne ta hanyar bakon amana da ya shigo amma ya ci amanar kasar domin yasan yana dauke da cutar.</ORIGINAL_TEXT>
<TOKEN end_char="265" id="token-3-0" morph="none" pos="word" start_char="261">Kamar</TOKEN>
<TOKEN end_char="271" id="token-3-1" morph="none" pos="word" start_char="267">yadda</TOKEN>
<TOKEN end_char="275" id="token-3-2" morph="none" pos="word" start_char="273">aka</TOKEN>
<TOKEN end_char="280" id="token-3-3" morph="none" pos="word" start_char="277">sani</TOKEN>
<TOKEN end_char="286" id="token-3-4" morph="none" pos="word" start_char="282">cutar</TOKEN>
<TOKEN end_char="289" id="token-3-5" morph="none" pos="word" start_char="288">ta</TOKEN>
<TOKEN end_char="295" id="token-3-6" morph="none" pos="word" start_char="291">shigo</TOKEN>
<TOKEN end_char="298" id="token-3-7" morph="none" pos="word" start_char="297">ne</TOKEN>
<TOKEN end_char="301" id="token-3-8" morph="none" pos="word" start_char="300">ta</TOKEN>
<TOKEN end_char="308" id="token-3-9" morph="none" pos="word" start_char="303">hanyar</TOKEN>
<TOKEN end_char="314" id="token-3-10" morph="none" pos="word" start_char="310">bakon</TOKEN>
<TOKEN end_char="320" id="token-3-11" morph="none" pos="word" start_char="316">amana</TOKEN>
<TOKEN end_char="323" id="token-3-12" morph="none" pos="word" start_char="322">da</TOKEN>
<TOKEN end_char="326" id="token-3-13" morph="none" pos="word" start_char="325">ya</TOKEN>
<TOKEN end_char="332" id="token-3-14" morph="none" pos="word" start_char="328">shigo</TOKEN>
<TOKEN end_char="337" id="token-3-15" morph="none" pos="word" start_char="334">amma</TOKEN>
<TOKEN end_char="340" id="token-3-16" morph="none" pos="word" start_char="339">ya</TOKEN>
<TOKEN end_char="343" id="token-3-17" morph="none" pos="word" start_char="342">ci</TOKEN>
<TOKEN end_char="350" id="token-3-18" morph="none" pos="word" start_char="345">amanar</TOKEN>
<TOKEN end_char="356" id="token-3-19" morph="none" pos="word" start_char="352">kasar</TOKEN>
<TOKEN end_char="362" id="token-3-20" morph="none" pos="word" start_char="358">domin</TOKEN>
<TOKEN end_char="368" id="token-3-21" morph="none" pos="word" start_char="364">yasan</TOKEN>
<TOKEN end_char="373" id="token-3-22" morph="none" pos="word" start_char="370">yana</TOKEN>
<TOKEN end_char="379" id="token-3-23" morph="none" pos="word" start_char="375">dauke</TOKEN>
<TOKEN end_char="382" id="token-3-24" morph="none" pos="word" start_char="381">da</TOKEN>
<TOKEN end_char="388" id="token-3-25" morph="none" pos="word" start_char="384">cutar</TOKEN>
<TOKEN end_char="389" id="token-3-26" morph="none" pos="punct" start_char="389">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>