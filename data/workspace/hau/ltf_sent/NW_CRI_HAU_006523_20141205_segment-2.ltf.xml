<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
<DOC id="NW_CRI_HAU_006523_20141205">
<TEXT>
<SEG end_char="451" id="segment-2" start_char="342">
<ORIGINAL_TEXT>Ta kuma bayyana cewa, kasar Sin za ta hada kai da kasar Kenya don ganin an gudanar da bincike yadda ya kamata.</ORIGINAL_TEXT>
<TOKEN end_char="343" id="token-2-0" morph="none" pos="word" start_char="342">Ta</TOKEN>
<TOKEN end_char="348" id="token-2-1" morph="none" pos="word" start_char="345">kuma</TOKEN>
<TOKEN end_char="356" id="token-2-2" morph="none" pos="word" start_char="350">bayyana</TOKEN>
<TOKEN end_char="361" id="token-2-3" morph="none" pos="word" start_char="358">cewa</TOKEN>
<TOKEN end_char="362" id="token-2-4" morph="none" pos="punct" start_char="362">,</TOKEN>
<TOKEN end_char="368" id="token-2-5" morph="none" pos="word" start_char="364">kasar</TOKEN>
<TOKEN end_char="372" id="token-2-6" morph="none" pos="word" start_char="370">Sin</TOKEN>
<TOKEN end_char="375" id="token-2-7" morph="none" pos="word" start_char="374">za</TOKEN>
<TOKEN end_char="378" id="token-2-8" morph="none" pos="word" start_char="377">ta</TOKEN>
<TOKEN end_char="383" id="token-2-9" morph="none" pos="word" start_char="380">hada</TOKEN>
<TOKEN end_char="387" id="token-2-10" morph="none" pos="word" start_char="385">kai</TOKEN>
<TOKEN end_char="390" id="token-2-11" morph="none" pos="word" start_char="389">da</TOKEN>
<TOKEN end_char="396" id="token-2-12" morph="none" pos="word" start_char="392">kasar</TOKEN>
<TOKEN end_char="402" id="token-2-13" morph="none" pos="word" start_char="398">Kenya</TOKEN>
<TOKEN end_char="406" id="token-2-14" morph="none" pos="word" start_char="404">don</TOKEN>
<TOKEN end_char="412" id="token-2-15" morph="none" pos="word" start_char="408">ganin</TOKEN>
<TOKEN end_char="415" id="token-2-16" morph="none" pos="word" start_char="414">an</TOKEN>
<TOKEN end_char="423" id="token-2-17" morph="none" pos="word" start_char="417">gudanar</TOKEN>
<TOKEN end_char="426" id="token-2-18" morph="none" pos="word" start_char="425">da</TOKEN>
<TOKEN end_char="434" id="token-2-19" morph="none" pos="word" start_char="428">bincike</TOKEN>
<TOKEN end_char="440" id="token-2-20" morph="none" pos="word" start_char="436">yadda</TOKEN>
<TOKEN end_char="443" id="token-2-21" morph="none" pos="word" start_char="442">ya</TOKEN>
<TOKEN end_char="450" id="token-2-22" morph="none" pos="word" start_char="445">kamata</TOKEN>
<TOKEN end_char="451" id="token-2-23" morph="none" pos="punct" start_char="451">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>