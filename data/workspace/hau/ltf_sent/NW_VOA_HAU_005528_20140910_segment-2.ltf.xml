<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
<DOC id="NW_VOA_HAU_005528_20140910">
<TEXT>
<SEG end_char="241" id="segment-2" start_char="150">
<ORIGINAL_TEXT>Ta wayar dasu akan yadda ake kamuwa da cutar da kuma abun da zasu yi su kauce kamuwa da ita.</ORIGINAL_TEXT>
<TOKEN end_char="151" id="token-2-0" morph="none" pos="word" start_char="150">Ta</TOKEN>
<TOKEN end_char="157" id="token-2-1" morph="none" pos="word" start_char="153">wayar</TOKEN>
<TOKEN end_char="162" id="token-2-2" morph="none" pos="word" start_char="159">dasu</TOKEN>
<TOKEN end_char="167" id="token-2-3" morph="none" pos="word" start_char="164">akan</TOKEN>
<TOKEN end_char="173" id="token-2-4" morph="none" pos="word" start_char="169">yadda</TOKEN>
<TOKEN end_char="177" id="token-2-5" morph="none" pos="word" start_char="175">ake</TOKEN>
<TOKEN end_char="184" id="token-2-6" morph="none" pos="word" start_char="179">kamuwa</TOKEN>
<TOKEN end_char="187" id="token-2-7" morph="none" pos="word" start_char="186">da</TOKEN>
<TOKEN end_char="193" id="token-2-8" morph="none" pos="word" start_char="189">cutar</TOKEN>
<TOKEN end_char="196" id="token-2-9" morph="none" pos="word" start_char="195">da</TOKEN>
<TOKEN end_char="201" id="token-2-10" morph="none" pos="word" start_char="198">kuma</TOKEN>
<TOKEN end_char="206" id="token-2-11" morph="none" pos="word" start_char="203">abun</TOKEN>
<TOKEN end_char="209" id="token-2-12" morph="none" pos="word" start_char="208">da</TOKEN>
<TOKEN end_char="214" id="token-2-13" morph="none" pos="word" start_char="211">zasu</TOKEN>
<TOKEN end_char="217" id="token-2-14" morph="none" pos="word" start_char="216">yi</TOKEN>
<TOKEN end_char="220" id="token-2-15" morph="none" pos="word" start_char="219">su</TOKEN>
<TOKEN end_char="226" id="token-2-16" morph="none" pos="word" start_char="222">kauce</TOKEN>
<TOKEN end_char="233" id="token-2-17" morph="none" pos="word" start_char="228">kamuwa</TOKEN>
<TOKEN end_char="236" id="token-2-18" morph="none" pos="word" start_char="235">da</TOKEN>
<TOKEN end_char="240" id="token-2-19" morph="none" pos="word" start_char="238">ita</TOKEN>
<TOKEN end_char="241" id="token-2-20" morph="none" pos="punct" start_char="241">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>