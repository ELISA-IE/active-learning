<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
<DOC id="WL_DAN_HAU_007447_20110711">
<TEXT>
<SEG end_char="2048" id="segment-12" start_char="1846">
<ORIGINAL_TEXT>Misalin an bawa yan China dama suna shigo da hajarsu daga kasarsu suna talla, da kuwa mutanen Kano ke zuwa kasashen nasu suna siyowa, suna kuma tafiya musu abinda suke bukata daga nan suna siyarwa a can.</ORIGINAL_TEXT>
<TOKEN end_char="1852" id="token-12-0" morph="none" pos="word" start_char="1846">Misalin</TOKEN>
<TOKEN end_char="1855" id="token-12-1" morph="none" pos="word" start_char="1854">an</TOKEN>
<TOKEN end_char="1860" id="token-12-2" morph="none" pos="word" start_char="1857">bawa</TOKEN>
<TOKEN end_char="1864" id="token-12-3" morph="none" pos="word" start_char="1862">yan</TOKEN>
<TOKEN end_char="1870" id="token-12-4" morph="none" pos="word" start_char="1866">China</TOKEN>
<TOKEN end_char="1875" id="token-12-5" morph="none" pos="word" start_char="1872">dama</TOKEN>
<TOKEN end_char="1880" id="token-12-6" morph="none" pos="word" start_char="1877">suna</TOKEN>
<TOKEN end_char="1886" id="token-12-7" morph="none" pos="word" start_char="1882">shigo</TOKEN>
<TOKEN end_char="1889" id="token-12-8" morph="none" pos="word" start_char="1888">da</TOKEN>
<TOKEN end_char="1897" id="token-12-9" morph="none" pos="word" start_char="1891">hajarsu</TOKEN>
<TOKEN end_char="1902" id="token-12-10" morph="none" pos="word" start_char="1899">daga</TOKEN>
<TOKEN end_char="1910" id="token-12-11" morph="none" pos="word" start_char="1904">kasarsu</TOKEN>
<TOKEN end_char="1915" id="token-12-12" morph="none" pos="word" start_char="1912">suna</TOKEN>
<TOKEN end_char="1921" id="token-12-13" morph="none" pos="word" start_char="1917">talla</TOKEN>
<TOKEN end_char="1922" id="token-12-14" morph="none" pos="punct" start_char="1922">,</TOKEN>
<TOKEN end_char="1925" id="token-12-15" morph="none" pos="word" start_char="1924">da</TOKEN>
<TOKEN end_char="1930" id="token-12-16" morph="none" pos="word" start_char="1927">kuwa</TOKEN>
<TOKEN end_char="1938" id="token-12-17" morph="none" pos="word" start_char="1932">mutanen</TOKEN>
<TOKEN end_char="1943" id="token-12-18" morph="none" pos="word" start_char="1940">Kano</TOKEN>
<TOKEN end_char="1946" id="token-12-19" morph="none" pos="word" start_char="1945">ke</TOKEN>
<TOKEN end_char="1951" id="token-12-20" morph="none" pos="word" start_char="1948">zuwa</TOKEN>
<TOKEN end_char="1960" id="token-12-21" morph="none" pos="word" start_char="1953">kasashen</TOKEN>
<TOKEN end_char="1965" id="token-12-22" morph="none" pos="word" start_char="1962">nasu</TOKEN>
<TOKEN end_char="1970" id="token-12-23" morph="none" pos="word" start_char="1967">suna</TOKEN>
<TOKEN end_char="1977" id="token-12-24" morph="none" pos="word" start_char="1972">siyowa</TOKEN>
<TOKEN end_char="1978" id="token-12-25" morph="none" pos="punct" start_char="1978">,</TOKEN>
<TOKEN end_char="1983" id="token-12-26" morph="none" pos="word" start_char="1980">suna</TOKEN>
<TOKEN end_char="1988" id="token-12-27" morph="none" pos="word" start_char="1985">kuma</TOKEN>
<TOKEN end_char="1995" id="token-12-28" morph="none" pos="word" start_char="1990">tafiya</TOKEN>
<TOKEN end_char="2000" id="token-12-29" morph="none" pos="word" start_char="1997">musu</TOKEN>
<TOKEN end_char="2007" id="token-12-30" morph="none" pos="word" start_char="2002">abinda</TOKEN>
<TOKEN end_char="2012" id="token-12-31" morph="none" pos="word" start_char="2009">suke</TOKEN>
<TOKEN end_char="2019" id="token-12-32" morph="none" pos="word" start_char="2014">bukata</TOKEN>
<TOKEN end_char="2024" id="token-12-33" morph="none" pos="word" start_char="2021">daga</TOKEN>
<TOKEN end_char="2028" id="token-12-34" morph="none" pos="word" start_char="2026">nan</TOKEN>
<TOKEN end_char="2033" id="token-12-35" morph="none" pos="word" start_char="2030">suna</TOKEN>
<TOKEN end_char="2041" id="token-12-36" morph="none" pos="word" start_char="2035">siyarwa</TOKEN>
<TOKEN end_char="2043" id="token-12-37" morph="none" pos="word" start_char="2043">a</TOKEN>
<TOKEN end_char="2047" id="token-12-38" morph="none" pos="word" start_char="2045">can</TOKEN>
<TOKEN end_char="2048" id="token-12-39" morph="none" pos="punct" start_char="2048">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>