<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
<DOC id="NW_VOA_HAU_002242_20120904">
<TEXT>
<SEG end_char="625" id="segment-2" start_char="433">
<ORIGINAL_TEXT>Mr. Al-Nssir ya bayyana cewa, ana samun ci gaba a wannan yunkurin kasancewa an sami raguwar wadanda ke kamuwa da cutar a kasashen da cutar tafi yawa, da kuma tsakanin matasa a duniya baki daya.</ORIGINAL_TEXT>
<TOKEN end_char="434" id="token-2-0" morph="none" pos="word" start_char="433">Mr</TOKEN>
<TOKEN end_char="435" id="token-2-1" morph="none" pos="punct" start_char="435">.</TOKEN>
<TOKEN end_char="438" id="token-2-2" morph="none" pos="word" start_char="437">Al</TOKEN>
<TOKEN end_char="439" id="token-2-3" morph="none" pos="punct" start_char="439">-</TOKEN>
<TOKEN end_char="444" id="token-2-4" morph="none" pos="word" start_char="440">Nssir</TOKEN>
<TOKEN end_char="447" id="token-2-5" morph="none" pos="word" start_char="446">ya</TOKEN>
<TOKEN end_char="455" id="token-2-6" morph="none" pos="word" start_char="449">bayyana</TOKEN>
<TOKEN end_char="460" id="token-2-7" morph="none" pos="word" start_char="457">cewa</TOKEN>
<TOKEN end_char="461" id="token-2-8" morph="none" pos="punct" start_char="461">,</TOKEN>
<TOKEN end_char="465" id="token-2-9" morph="none" pos="word" start_char="463">ana</TOKEN>
<TOKEN end_char="471" id="token-2-10" morph="none" pos="word" start_char="467">samun</TOKEN>
<TOKEN end_char="474" id="token-2-11" morph="none" pos="word" start_char="473">ci</TOKEN>
<TOKEN end_char="479" id="token-2-12" morph="none" pos="word" start_char="476">gaba</TOKEN>
<TOKEN end_char="481" id="token-2-13" morph="none" pos="word" start_char="481">a</TOKEN>
<TOKEN end_char="488" id="token-2-14" morph="none" pos="word" start_char="483">wannan</TOKEN>
<TOKEN end_char="497" id="token-2-15" morph="none" pos="word" start_char="490">yunkurin</TOKEN>
<TOKEN end_char="507" id="token-2-16" morph="none" pos="word" start_char="499">kasancewa</TOKEN>
<TOKEN end_char="510" id="token-2-17" morph="none" pos="word" start_char="509">an</TOKEN>
<TOKEN end_char="515" id="token-2-18" morph="none" pos="word" start_char="512">sami</TOKEN>
<TOKEN end_char="523" id="token-2-19" morph="none" pos="word" start_char="517">raguwar</TOKEN>
<TOKEN end_char="531" id="token-2-20" morph="none" pos="word" start_char="525">wadanda</TOKEN>
<TOKEN end_char="534" id="token-2-21" morph="none" pos="word" start_char="533">ke</TOKEN>
<TOKEN end_char="541" id="token-2-22" morph="none" pos="word" start_char="536">kamuwa</TOKEN>
<TOKEN end_char="544" id="token-2-23" morph="none" pos="word" start_char="543">da</TOKEN>
<TOKEN end_char="550" id="token-2-24" morph="none" pos="word" start_char="546">cutar</TOKEN>
<TOKEN end_char="552" id="token-2-25" morph="none" pos="word" start_char="552">a</TOKEN>
<TOKEN end_char="561" id="token-2-26" morph="none" pos="word" start_char="554">kasashen</TOKEN>
<TOKEN end_char="564" id="token-2-27" morph="none" pos="word" start_char="563">da</TOKEN>
<TOKEN end_char="570" id="token-2-28" morph="none" pos="word" start_char="566">cutar</TOKEN>
<TOKEN end_char="575" id="token-2-29" morph="none" pos="word" start_char="572">tafi</TOKEN>
<TOKEN end_char="580" id="token-2-30" morph="none" pos="word" start_char="577">yawa</TOKEN>
<TOKEN end_char="581" id="token-2-31" morph="none" pos="punct" start_char="581">,</TOKEN>
<TOKEN end_char="584" id="token-2-32" morph="none" pos="word" start_char="583">da</TOKEN>
<TOKEN end_char="589" id="token-2-33" morph="none" pos="word" start_char="586">kuma</TOKEN>
<TOKEN end_char="598" id="token-2-34" morph="none" pos="word" start_char="591">tsakanin</TOKEN>
<TOKEN end_char="605" id="token-2-35" morph="none" pos="word" start_char="600">matasa</TOKEN>
<TOKEN end_char="607" id="token-2-36" morph="none" pos="word" start_char="607">a</TOKEN>
<TOKEN end_char="614" id="token-2-37" morph="none" pos="word" start_char="609">duniya</TOKEN>
<TOKEN end_char="619" id="token-2-38" morph="none" pos="word" start_char="616">baki</TOKEN>
<TOKEN end_char="624" id="token-2-39" morph="none" pos="word" start_char="621">daya</TOKEN>
<TOKEN end_char="625" id="token-2-40" morph="none" pos="punct" start_char="625">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>