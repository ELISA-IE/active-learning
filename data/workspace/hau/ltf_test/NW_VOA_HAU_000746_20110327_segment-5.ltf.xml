<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
<DOC id="NW_VOA_HAU_000746_20110327">
<TEXT>
<SEG end_char="1140" id="segment-5" start_char="956">
<ORIGINAL_TEXT>Sai dai jamiÊ¼an suka ce nan da nan tekun zai dama ruwan da yake dauke da gubar kuma, bashi da wani hadari ga halittu dake cikin ruwa ko kuma illa ga abincin da ake samu daga cikin teku.</ORIGINAL_TEXT>
<TOKEN end_char="958" id="token-5-0" morph="none" pos="word" start_char="956">Sai</TOKEN>
<TOKEN end_char="962" id="token-5-1" morph="none" pos="word" start_char="960">dai</TOKEN>
<TOKEN end_char="970" id="token-5-2" morph="none" pos="word" start_char="964">jamiÊ¼an</TOKEN>
<TOKEN end_char="975" id="token-5-3" morph="none" pos="word" start_char="972">suka</TOKEN>
<TOKEN end_char="978" id="token-5-4" morph="none" pos="word" start_char="977">ce</TOKEN>
<TOKEN end_char="982" id="token-5-5" morph="none" pos="word" start_char="980">nan</TOKEN>
<TOKEN end_char="985" id="token-5-6" morph="none" pos="word" start_char="984">da</TOKEN>
<TOKEN end_char="989" id="token-5-7" morph="none" pos="word" start_char="987">nan</TOKEN>
<TOKEN end_char="995" id="token-5-8" morph="none" pos="word" start_char="991">tekun</TOKEN>
<TOKEN end_char="999" id="token-5-9" morph="none" pos="word" start_char="997">zai</TOKEN>
<TOKEN end_char="1004" id="token-5-10" morph="none" pos="word" start_char="1001">dama</TOKEN>
<TOKEN end_char="1010" id="token-5-11" morph="none" pos="word" start_char="1006">ruwan</TOKEN>
<TOKEN end_char="1013" id="token-5-12" morph="none" pos="word" start_char="1012">da</TOKEN>
<TOKEN end_char="1018" id="token-5-13" morph="none" pos="word" start_char="1015">yake</TOKEN>
<TOKEN end_char="1024" id="token-5-14" morph="none" pos="word" start_char="1020">dauke</TOKEN>
<TOKEN end_char="1027" id="token-5-15" morph="none" pos="word" start_char="1026">da</TOKEN>
<TOKEN end_char="1033" id="token-5-16" morph="none" pos="word" start_char="1029">gubar</TOKEN>
<TOKEN end_char="1038" id="token-5-17" morph="none" pos="word" start_char="1035">kuma</TOKEN>
<TOKEN end_char="1039" id="token-5-18" morph="none" pos="punct" start_char="1039">,</TOKEN>
<TOKEN end_char="1045" id="token-5-19" morph="none" pos="word" start_char="1041">bashi</TOKEN>
<TOKEN end_char="1048" id="token-5-20" morph="none" pos="word" start_char="1047">da</TOKEN>
<TOKEN end_char="1053" id="token-5-21" morph="none" pos="word" start_char="1050">wani</TOKEN>
<TOKEN end_char="1060" id="token-5-22" morph="none" pos="word" start_char="1055">hadari</TOKEN>
<TOKEN end_char="1063" id="token-5-23" morph="none" pos="word" start_char="1062">ga</TOKEN>
<TOKEN end_char="1071" id="token-5-24" morph="none" pos="word" start_char="1065">halittu</TOKEN>
<TOKEN end_char="1076" id="token-5-25" morph="none" pos="word" start_char="1073">dake</TOKEN>
<TOKEN end_char="1082" id="token-5-26" morph="none" pos="word" start_char="1078">cikin</TOKEN>
<TOKEN end_char="1087" id="token-5-27" morph="none" pos="word" start_char="1084">ruwa</TOKEN>
<TOKEN end_char="1090" id="token-5-28" morph="none" pos="word" start_char="1089">ko</TOKEN>
<TOKEN end_char="1095" id="token-5-29" morph="none" pos="word" start_char="1092">kuma</TOKEN>
<TOKEN end_char="1100" id="token-5-30" morph="none" pos="word" start_char="1097">illa</TOKEN>
<TOKEN end_char="1103" id="token-5-31" morph="none" pos="word" start_char="1102">ga</TOKEN>
<TOKEN end_char="1111" id="token-5-32" morph="none" pos="word" start_char="1105">abincin</TOKEN>
<TOKEN end_char="1114" id="token-5-33" morph="none" pos="word" start_char="1113">da</TOKEN>
<TOKEN end_char="1118" id="token-5-34" morph="none" pos="word" start_char="1116">ake</TOKEN>
<TOKEN end_char="1123" id="token-5-35" morph="none" pos="word" start_char="1120">samu</TOKEN>
<TOKEN end_char="1128" id="token-5-36" morph="none" pos="word" start_char="1125">daga</TOKEN>
<TOKEN end_char="1134" id="token-5-37" morph="none" pos="word" start_char="1130">cikin</TOKEN>
<TOKEN end_char="1139" id="token-5-38" morph="none" pos="word" start_char="1136">teku</TOKEN>
<TOKEN end_char="1140" id="token-5-39" morph="none" pos="punct" start_char="1140">.</TOKEN>
</SEG>
</TEXT>
</DOC>
</LCTL_TEXT>