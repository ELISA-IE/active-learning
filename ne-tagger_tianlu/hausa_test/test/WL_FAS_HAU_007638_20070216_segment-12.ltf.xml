<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="WL_FAS_HAU_007638_20070216_segment-12">
    <TEXT><SEG id="segment-12" start_char="1624" end_char="1818">
<ORIGINAL_TEXT>Daga cikin kayatattun hanyoyin sadarwan da iPaq 500 Series ke dauke dasu, kana iya sauraron sakonnin da aka aiko maka a rubuce, cikin sauti, ka kuma aika da jawabi cikin sauti, a samesu a rubuce.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1624" end_char="1627">Daga</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1629" end_char="1633">cikin</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1635" end_char="1644">kayatattun</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1646" end_char="1653">hanyoyin</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1655" end_char="1662">sadarwan</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1664" end_char="1665">da</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1667" end_char="1670">iPaq</TOKEN>
<TOKEN id="token-12-7" pos="number" morph="none" start_char="1672" end_char="1674">500</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1676" end_char="1681">Series</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1683" end_char="1684">ke</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1686" end_char="1690">dauke</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1692" end_char="1695">dasu</TOKEN>
<TOKEN id="token-12-12" pos="punct" morph="none" start_char="1696" end_char="1696">,</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1698" end_char="1701">kana</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1703" end_char="1705">iya</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1707" end_char="1714">sauraron</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1716" end_char="1723">sakonnin</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1725" end_char="1726">da</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1728" end_char="1730">aka</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1732" end_char="1735">aiko</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1737" end_char="1740">maka</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1742" end_char="1742">a</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1744" end_char="1749">rubuce</TOKEN>
<TOKEN id="token-12-23" pos="punct" morph="none" start_char="1750" end_char="1750">,</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1752" end_char="1756">cikin</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1758" end_char="1762">sauti</TOKEN>
<TOKEN id="token-12-26" pos="punct" morph="none" start_char="1763" end_char="1763">,</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1765" end_char="1766">ka</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="1768" end_char="1771">kuma</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1773" end_char="1776">aika</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="1778" end_char="1779">da</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="1781" end_char="1786">jawabi</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="1788" end_char="1792">cikin</TOKEN>
<TOKEN id="token-12-33" pos="word" morph="none" start_char="1794" end_char="1798">sauti</TOKEN>
<TOKEN id="token-12-34" pos="punct" morph="none" start_char="1799" end_char="1799">,</TOKEN>
<TOKEN id="token-12-35" pos="word" morph="none" start_char="1801" end_char="1801">a</TOKEN>
<TOKEN id="token-12-36" pos="word" morph="none" start_char="1803" end_char="1808">samesu</TOKEN>
<TOKEN id="token-12-37" pos="word" morph="none" start_char="1810" end_char="1810">a</TOKEN>
<TOKEN id="token-12-38" pos="word" morph="none" start_char="1812" end_char="1817">rubuce</TOKEN>
<TOKEN id="token-12-39" pos="punct" morph="none" start_char="1818" end_char="1818">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
