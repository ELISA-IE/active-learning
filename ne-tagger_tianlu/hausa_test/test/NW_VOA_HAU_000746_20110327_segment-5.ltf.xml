<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_VOA_HAU_000746_20110327_segment-5">
    <TEXT><SEG id="segment-5" start_char="956" end_char="1140">
<ORIGINAL_TEXT>Sai dai jamiÊ¼an suka ce nan da nan tekun zai dama ruwan da yake dauke da gubar kuma, bashi da wani hadari ga halittu dake cikin ruwa ko kuma illa ga abincin da ake samu daga cikin teku.</ORIGINAL_TEXT>
<TOKEN id="token-5-0" pos="word" morph="none" start_char="956" end_char="958">Sai</TOKEN>
<TOKEN id="token-5-1" pos="word" morph="none" start_char="960" end_char="962">dai</TOKEN>
<TOKEN id="token-5-2" pos="word" morph="none" start_char="964" end_char="970">jamiÊ¼an</TOKEN>
<TOKEN id="token-5-3" pos="word" morph="none" start_char="972" end_char="975">suka</TOKEN>
<TOKEN id="token-5-4" pos="word" morph="none" start_char="977" end_char="978">ce</TOKEN>
<TOKEN id="token-5-5" pos="word" morph="none" start_char="980" end_char="982">nan</TOKEN>
<TOKEN id="token-5-6" pos="word" morph="none" start_char="984" end_char="985">da</TOKEN>
<TOKEN id="token-5-7" pos="word" morph="none" start_char="987" end_char="989">nan</TOKEN>
<TOKEN id="token-5-8" pos="word" morph="none" start_char="991" end_char="995">tekun</TOKEN>
<TOKEN id="token-5-9" pos="word" morph="none" start_char="997" end_char="999">zai</TOKEN>
<TOKEN id="token-5-10" pos="word" morph="none" start_char="1001" end_char="1004">dama</TOKEN>
<TOKEN id="token-5-11" pos="word" morph="none" start_char="1006" end_char="1010">ruwan</TOKEN>
<TOKEN id="token-5-12" pos="word" morph="none" start_char="1012" end_char="1013">da</TOKEN>
<TOKEN id="token-5-13" pos="word" morph="none" start_char="1015" end_char="1018">yake</TOKEN>
<TOKEN id="token-5-14" pos="word" morph="none" start_char="1020" end_char="1024">dauke</TOKEN>
<TOKEN id="token-5-15" pos="word" morph="none" start_char="1026" end_char="1027">da</TOKEN>
<TOKEN id="token-5-16" pos="word" morph="none" start_char="1029" end_char="1033">gubar</TOKEN>
<TOKEN id="token-5-17" pos="word" morph="none" start_char="1035" end_char="1038">kuma</TOKEN>
<TOKEN id="token-5-18" pos="punct" morph="none" start_char="1039" end_char="1039">,</TOKEN>
<TOKEN id="token-5-19" pos="word" morph="none" start_char="1041" end_char="1045">bashi</TOKEN>
<TOKEN id="token-5-20" pos="word" morph="none" start_char="1047" end_char="1048">da</TOKEN>
<TOKEN id="token-5-21" pos="word" morph="none" start_char="1050" end_char="1053">wani</TOKEN>
<TOKEN id="token-5-22" pos="word" morph="none" start_char="1055" end_char="1060">hadari</TOKEN>
<TOKEN id="token-5-23" pos="word" morph="none" start_char="1062" end_char="1063">ga</TOKEN>
<TOKEN id="token-5-24" pos="word" morph="none" start_char="1065" end_char="1071">halittu</TOKEN>
<TOKEN id="token-5-25" pos="word" morph="none" start_char="1073" end_char="1076">dake</TOKEN>
<TOKEN id="token-5-26" pos="word" morph="none" start_char="1078" end_char="1082">cikin</TOKEN>
<TOKEN id="token-5-27" pos="word" morph="none" start_char="1084" end_char="1087">ruwa</TOKEN>
<TOKEN id="token-5-28" pos="word" morph="none" start_char="1089" end_char="1090">ko</TOKEN>
<TOKEN id="token-5-29" pos="word" morph="none" start_char="1092" end_char="1095">kuma</TOKEN>
<TOKEN id="token-5-30" pos="word" morph="none" start_char="1097" end_char="1100">illa</TOKEN>
<TOKEN id="token-5-31" pos="word" morph="none" start_char="1102" end_char="1103">ga</TOKEN>
<TOKEN id="token-5-32" pos="word" morph="none" start_char="1105" end_char="1111">abincin</TOKEN>
<TOKEN id="token-5-33" pos="word" morph="none" start_char="1113" end_char="1114">da</TOKEN>
<TOKEN id="token-5-34" pos="word" morph="none" start_char="1116" end_char="1118">ake</TOKEN>
<TOKEN id="token-5-35" pos="word" morph="none" start_char="1120" end_char="1123">samu</TOKEN>
<TOKEN id="token-5-36" pos="word" morph="none" start_char="1125" end_char="1128">daga</TOKEN>
<TOKEN id="token-5-37" pos="word" morph="none" start_char="1130" end_char="1134">cikin</TOKEN>
<TOKEN id="token-5-38" pos="word" morph="none" start_char="1136" end_char="1139">teku</TOKEN>
<TOKEN id="token-5-39" pos="punct" morph="none" start_char="1140" end_char="1140">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
