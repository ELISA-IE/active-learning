<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_VOA_HAU_002188_20120807_segment-4">
    <TEXT><SEG id="segment-4" start_char="1014" end_char="1314">
<ORIGINAL_TEXT>NaÊ¼urorin kumbon Curiosity masu aiki da karfin nukiliya, zasu shafe shekaru biyu su na bincike da tabe-tabe da sunsuno ko an taba samun wata halitta a kan duniyar, ko kuma akwai abubuwan da zasu iya kyale halitta ta rayu a kan wannan curin jar kasa, wadda daga nan duniya ake hango ta kamar tauraruwa.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="1014" end_char="1022">NaÊ¼urorin</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="1024" end_char="1029">kumbon</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="1031" end_char="1039">Curiosity</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="1041" end_char="1044">masu</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="1046" end_char="1049">aiki</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="1051" end_char="1052">da</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="1054" end_char="1059">karfin</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="1061" end_char="1068">nukiliya</TOKEN>
<TOKEN id="token-4-8" pos="punct" morph="none" start_char="1069" end_char="1069">,</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="1071" end_char="1074">zasu</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="1076" end_char="1080">shafe</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="1082" end_char="1088">shekaru</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="1090" end_char="1093">biyu</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="1095" end_char="1096">su</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="1098" end_char="1099">na</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="1101" end_char="1107">bincike</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="1109" end_char="1110">da</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="1112" end_char="1115">tabe</TOKEN>
<TOKEN id="token-4-18" pos="punct" morph="none" start_char="1116" end_char="1116">-</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="1117" end_char="1120">tabe</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="1122" end_char="1123">da</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="1125" end_char="1131">sunsuno</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="1133" end_char="1134">ko</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="1136" end_char="1137">an</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="1139" end_char="1142">taba</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="1144" end_char="1148">samun</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="1150" end_char="1153">wata</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="1155" end_char="1161">halitta</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="1163" end_char="1163">a</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="1165" end_char="1167">kan</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="1169" end_char="1175">duniyar</TOKEN>
<TOKEN id="token-4-31" pos="punct" morph="none" start_char="1176" end_char="1176">,</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="1178" end_char="1179">ko</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="1181" end_char="1184">kuma</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="1186" end_char="1190">akwai</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="1192" end_char="1199">abubuwan</TOKEN>
<TOKEN id="token-4-36" pos="word" morph="none" start_char="1201" end_char="1202">da</TOKEN>
<TOKEN id="token-4-37" pos="word" morph="none" start_char="1204" end_char="1207">zasu</TOKEN>
<TOKEN id="token-4-38" pos="word" morph="none" start_char="1209" end_char="1211">iya</TOKEN>
<TOKEN id="token-4-39" pos="word" morph="none" start_char="1213" end_char="1217">kyale</TOKEN>
<TOKEN id="token-4-40" pos="word" morph="none" start_char="1219" end_char="1225">halitta</TOKEN>
<TOKEN id="token-4-41" pos="word" morph="none" start_char="1227" end_char="1228">ta</TOKEN>
<TOKEN id="token-4-42" pos="word" morph="none" start_char="1230" end_char="1233">rayu</TOKEN>
<TOKEN id="token-4-43" pos="word" morph="none" start_char="1235" end_char="1235">a</TOKEN>
<TOKEN id="token-4-44" pos="word" morph="none" start_char="1237" end_char="1239">kan</TOKEN>
<TOKEN id="token-4-45" pos="word" morph="none" start_char="1241" end_char="1246">wannan</TOKEN>
<TOKEN id="token-4-46" pos="word" morph="none" start_char="1248" end_char="1252">curin</TOKEN>
<TOKEN id="token-4-47" pos="word" morph="none" start_char="1254" end_char="1256">jar</TOKEN>
<TOKEN id="token-4-48" pos="word" morph="none" start_char="1258" end_char="1261">kasa</TOKEN>
<TOKEN id="token-4-49" pos="punct" morph="none" start_char="1262" end_char="1262">,</TOKEN>
<TOKEN id="token-4-50" pos="word" morph="none" start_char="1264" end_char="1268">wadda</TOKEN>
<TOKEN id="token-4-51" pos="word" morph="none" start_char="1270" end_char="1273">daga</TOKEN>
<TOKEN id="token-4-52" pos="word" morph="none" start_char="1275" end_char="1277">nan</TOKEN>
<TOKEN id="token-4-53" pos="word" morph="none" start_char="1279" end_char="1284">duniya</TOKEN>
<TOKEN id="token-4-54" pos="word" morph="none" start_char="1286" end_char="1288">ake</TOKEN>
<TOKEN id="token-4-55" pos="word" morph="none" start_char="1290" end_char="1294">hango</TOKEN>
<TOKEN id="token-4-56" pos="word" morph="none" start_char="1296" end_char="1297">ta</TOKEN>
<TOKEN id="token-4-57" pos="word" morph="none" start_char="1299" end_char="1303">kamar</TOKEN>
<TOKEN id="token-4-58" pos="word" morph="none" start_char="1305" end_char="1313">tauraruwa</TOKEN>
<TOKEN id="token-4-59" pos="punct" morph="none" start_char="1314" end_char="1314">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
