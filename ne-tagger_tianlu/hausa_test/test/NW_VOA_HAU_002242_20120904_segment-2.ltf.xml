<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_VOA_HAU_002242_20120904_segment-2">
    <TEXT><SEG id="segment-2" start_char="433" end_char="625">
<ORIGINAL_TEXT>Mr. Al-Nssir ya bayyana cewa, ana samun ci gaba a wannan yunkurin kasancewa an sami raguwar wadanda ke kamuwa da cutar a kasashen da cutar tafi yawa, da kuma tsakanin matasa a duniya baki daya.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="433" end_char="434">Mr</TOKEN>
<TOKEN id="token-2-1" pos="punct" morph="none" start_char="435" end_char="435">.</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="437" end_char="438">Al</TOKEN>
<TOKEN id="token-2-3" pos="punct" morph="none" start_char="439" end_char="439">-</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="440" end_char="444">Nssir</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="446" end_char="447">ya</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="449" end_char="455">bayyana</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="457" end_char="460">cewa</TOKEN>
<TOKEN id="token-2-8" pos="punct" morph="none" start_char="461" end_char="461">,</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="463" end_char="465">ana</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="467" end_char="471">samun</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="473" end_char="474">ci</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="476" end_char="479">gaba</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="481" end_char="481">a</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="483" end_char="488">wannan</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="490" end_char="497">yunkurin</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="499" end_char="507">kasancewa</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="509" end_char="510">an</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="512" end_char="515">sami</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="517" end_char="523">raguwar</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="525" end_char="531">wadanda</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="533" end_char="534">ke</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="536" end_char="541">kamuwa</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="543" end_char="544">da</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="546" end_char="550">cutar</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="552" end_char="552">a</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="554" end_char="561">kasashen</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="563" end_char="564">da</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="566" end_char="570">cutar</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="572" end_char="575">tafi</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="577" end_char="580">yawa</TOKEN>
<TOKEN id="token-2-31" pos="punct" morph="none" start_char="581" end_char="581">,</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="583" end_char="584">da</TOKEN>
<TOKEN id="token-2-33" pos="word" morph="none" start_char="586" end_char="589">kuma</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="591" end_char="598">tsakanin</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="600" end_char="605">matasa</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="607" end_char="607">a</TOKEN>
<TOKEN id="token-2-37" pos="word" morph="none" start_char="609" end_char="614">duniya</TOKEN>
<TOKEN id="token-2-38" pos="word" morph="none" start_char="616" end_char="619">baki</TOKEN>
<TOKEN id="token-2-39" pos="word" morph="none" start_char="621" end_char="624">daya</TOKEN>
<TOKEN id="token-2-40" pos="punct" morph="none" start_char="625" end_char="625">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
