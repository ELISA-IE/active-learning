<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_VOA_HAU_002942_20130623_segment-4">
    <TEXT><SEG id="segment-4" start_char="614" end_char="822">
<ORIGINAL_TEXT>Wadanda ambaliyar ruwan ya shafa sun hada da masu ayyukan ibada dake kan hanyarsu zuwa wuraren ibadar Hindi da kuma Ê¼yan yawon bude ido, wadanda sai da aka yi amfani da jirgi mai saukar angulu kafin a ceto su.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="614" end_char="620">Wadanda</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="622" end_char="630">ambaliyar</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="632" end_char="636">ruwan</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="638" end_char="639">ya</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="641" end_char="645">shafa</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="647" end_char="649">sun</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="651" end_char="654">hada</TOKEN>
<TOKEN id="token-4-7" pos="word" morph="none" start_char="656" end_char="657">da</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="659" end_char="662">masu</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="664" end_char="670">ayyukan</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="672" end_char="676">ibada</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="678" end_char="681">dake</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="683" end_char="685">kan</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="687" end_char="694">hanyarsu</TOKEN>
<TOKEN id="token-4-14" pos="word" morph="none" start_char="696" end_char="699">zuwa</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="701" end_char="707">wuraren</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="709" end_char="714">ibadar</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="716" end_char="720">Hindi</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="722" end_char="723">da</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="725" end_char="728">kuma</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="730" end_char="733">Ê¼yan</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="735" end_char="739">yawon</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="741" end_char="744">bude</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="746" end_char="748">ido</TOKEN>
<TOKEN id="token-4-24" pos="punct" morph="none" start_char="749" end_char="749">,</TOKEN>
<TOKEN id="token-4-25" pos="word" morph="none" start_char="751" end_char="757">wadanda</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="759" end_char="761">sai</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="763" end_char="764">da</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="766" end_char="768">aka</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="770" end_char="771">yi</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="773" end_char="778">amfani</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="780" end_char="781">da</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="783" end_char="787">jirgi</TOKEN>
<TOKEN id="token-4-33" pos="word" morph="none" start_char="789" end_char="791">mai</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="793" end_char="798">saukar</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="800" end_char="805">angulu</TOKEN>
<TOKEN id="token-4-36" pos="word" morph="none" start_char="807" end_char="811">kafin</TOKEN>
<TOKEN id="token-4-37" pos="word" morph="none" start_char="813" end_char="813">a</TOKEN>
<TOKEN id="token-4-38" pos="word" morph="none" start_char="815" end_char="818">ceto</TOKEN>
<TOKEN id="token-4-39" pos="word" morph="none" start_char="820" end_char="821">su</TOKEN>
<TOKEN id="token-4-40" pos="punct" morph="none" start_char="822" end_char="822">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
