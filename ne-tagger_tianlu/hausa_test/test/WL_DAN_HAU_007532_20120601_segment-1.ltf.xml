<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="WL_DAN_HAU_007532_20120601_segment-1">
    <TEXT><SEG id="segment-1" start_char="32" end_char="232">
<ORIGINAL_TEXT>Rundunar tsaron hadin gwiwa a Kano da ke arewacin Nigeria, ta tabbatar da mutuwar wani dan kasar Jamus da aka sace jihar da kuma wasu mutane biyar a wata musayar wuta da aka yi da safiyar yau a birnin.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="32" end_char="39">Rundunar</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="41" end_char="46">tsaron</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="48" end_char="52">hadin</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="54" end_char="58">gwiwa</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="60" end_char="60">a</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="62" end_char="65">Kano</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="67" end_char="68">da</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="70" end_char="71">ke</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="73" end_char="80">arewacin</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="82" end_char="88">Nigeria</TOKEN>
<TOKEN id="token-1-10" pos="punct" morph="none" start_char="89" end_char="89">,</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="91" end_char="92">ta</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="94" end_char="101">tabbatar</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="103" end_char="104">da</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="106" end_char="112">mutuwar</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="114" end_char="117">wani</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="119" end_char="121">dan</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="123" end_char="127">kasar</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="129" end_char="133">Jamus</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="135" end_char="136">da</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="138" end_char="140">aka</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="142" end_char="145">sace</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="147" end_char="151">jihar</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="153" end_char="154">da</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="156" end_char="159">kuma</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="161" end_char="164">wasu</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="166" end_char="171">mutane</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="173" end_char="177">biyar</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="179" end_char="179">a</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="181" end_char="184">wata</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="186" end_char="192">musayar</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="194" end_char="197">wuta</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="199" end_char="200">da</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="202" end_char="204">aka</TOKEN>
<TOKEN id="token-1-34" pos="word" morph="none" start_char="206" end_char="207">yi</TOKEN>
<TOKEN id="token-1-35" pos="word" morph="none" start_char="209" end_char="210">da</TOKEN>
<TOKEN id="token-1-36" pos="word" morph="none" start_char="212" end_char="218">safiyar</TOKEN>
<TOKEN id="token-1-37" pos="word" morph="none" start_char="220" end_char="222">yau</TOKEN>
<TOKEN id="token-1-38" pos="word" morph="none" start_char="224" end_char="224">a</TOKEN>
<TOKEN id="token-1-39" pos="word" morph="none" start_char="226" end_char="231">birnin</TOKEN>
<TOKEN id="token-1-40" pos="punct" morph="none" start_char="232" end_char="232">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
