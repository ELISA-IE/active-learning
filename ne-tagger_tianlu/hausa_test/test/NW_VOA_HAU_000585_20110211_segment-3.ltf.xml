<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_VOA_HAU_000585_20110211_segment-3">
    <TEXT><SEG id="segment-3" start_char="584" end_char="806">
<ORIGINAL_TEXT>Kwararru daga bankin sunce sai tayu akwai mutane kamar milyan dubu daya dake fama yunwa a fadin Duniya baki daya ahalin yanzu.Tsadar abinci zata iya tilastawa talakawa su gwammace neman abinci mai makon jinya da neman ilmi.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="584" end_char="591">Kwararru</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="593" end_char="596">daga</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="598" end_char="603">bankin</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="605" end_char="609">sunce</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="611" end_char="613">sai</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="615" end_char="618">tayu</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="620" end_char="624">akwai</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="626" end_char="631">mutane</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="633" end_char="637">kamar</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="639" end_char="644">milyan</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="646" end_char="649">dubu</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="651" end_char="654">daya</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="656" end_char="659">dake</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="661" end_char="664">fama</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="666" end_char="670">yunwa</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="672" end_char="672">a</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="674" end_char="678">fadin</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="680" end_char="685">Duniya</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="687" end_char="690">baki</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="692" end_char="695">daya</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="697" end_char="702">ahalin</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="704" end_char="708">yanzu</TOKEN>
<TOKEN id="token-3-22" pos="punct" morph="none" start_char="709" end_char="709">.</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="710" end_char="715">Tsadar</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="717" end_char="722">abinci</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="724" end_char="727">zata</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="729" end_char="731">iya</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="733" end_char="741">tilastawa</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="743" end_char="750">talakawa</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="752" end_char="753">su</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="755" end_char="762">gwammace</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="764" end_char="768">neman</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="770" end_char="775">abinci</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="777" end_char="779">mai</TOKEN>
<TOKEN id="token-3-34" pos="word" morph="none" start_char="781" end_char="785">makon</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="787" end_char="791">jinya</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="793" end_char="794">da</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="796" end_char="800">neman</TOKEN>
<TOKEN id="token-3-38" pos="word" morph="none" start_char="802" end_char="805">ilmi</TOKEN>
<TOKEN id="token-3-39" pos="punct" morph="none" start_char="806" end_char="806">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
