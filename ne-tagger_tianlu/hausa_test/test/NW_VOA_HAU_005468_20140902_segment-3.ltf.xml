<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_VOA_HAU_005468_20140902_segment-3">
    <TEXT><SEG id="segment-3" start_char="261" end_char="389">
<ORIGINAL_TEXT>Kamar yadda aka sani cutar ta shigo ne ta hanyar bakon amana da ya shigo amma ya ci amanar kasar domin yasan yana dauke da cutar.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="261" end_char="265">Kamar</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="267" end_char="271">yadda</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="273" end_char="275">aka</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="277" end_char="280">sani</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="282" end_char="286">cutar</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="288" end_char="289">ta</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="291" end_char="295">shigo</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="297" end_char="298">ne</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="300" end_char="301">ta</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="303" end_char="308">hanyar</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="310" end_char="314">bakon</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="316" end_char="320">amana</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="322" end_char="323">da</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="325" end_char="326">ya</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="328" end_char="332">shigo</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="334" end_char="337">amma</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="339" end_char="340">ya</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="342" end_char="343">ci</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="345" end_char="350">amanar</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="352" end_char="356">kasar</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="358" end_char="362">domin</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="364" end_char="368">yasan</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="370" end_char="373">yana</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="375" end_char="379">dauke</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="381" end_char="382">da</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="384" end_char="388">cutar</TOKEN>
<TOKEN id="token-3-26" pos="punct" morph="none" start_char="389" end_char="389">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
