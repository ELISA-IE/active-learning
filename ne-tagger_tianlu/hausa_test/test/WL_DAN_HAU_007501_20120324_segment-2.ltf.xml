<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="WL_DAN_HAU_007501_20120324_segment-2">
    <TEXT><SEG id="segment-2" start_char="325" end_char="606">
<ORIGINAL_TEXT>El Rufai ya bayyana hakan ne a turakarsa dake shafin bayyana ra始ayi na Twitter, inda wani daga cikin mabiyansa (followers) yayi masa tambayar "Shin yana tunanin abinda ya faru a kasar Mali zai iya faruwa a kasar nan idan shugabanni basu kula da bukatun talakawan da suka zabe su ba?</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="NOUN" morph="El:el=NOUN" start_char="325" end_char="326">El</TOKEN>
<TOKEN id="token-2-1" pos="NOUN" morph="Rufai:rufai=NOUN" start_char="328" end_char="332">Rufai</TOKEN>
<TOKEN id="token-2-2" pos="PRON" morph="ya:ya=PRON_WSP_3SM" start_char="334" end_char="335">ya</TOKEN>
<TOKEN id="token-2-3" pos="VERB" morph="bayyana:bayyana=VERB" start_char="337" end_char="343">bayyana</TOKEN>
<TOKEN id="token-2-4" pos="ADV" morph="hakan:hakan=ADV" start_char="345" end_char="349">hakan</TOKEN>
<TOKEN id="token-2-5" pos="COPULA" morph="ne:ne=COPULA" start_char="351" end_char="352">ne</TOKEN>
<TOKEN id="token-2-6" pos="PREP" morph="a:a=PREP" start_char="354" end_char="354">a</TOKEN>
<TOKEN id="token-2-7" pos="NOUN" morph="turaka:turaka=NOUN rsa:rsa=POSS_3SM" start_char="356" end_char="364">turakarsa</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="unanalyzable" start_char="366" end_char="369">dake</TOKEN>
<TOKEN id="token-2-9" pos="NOUN" morph="shafi:shafi=NOUN n:n=CONSTRUCT" start_char="371" end_char="376">shafin</TOKEN>
<TOKEN id="token-2-10" pos="VERB" morph="bayyana:bayyana=VERB" start_char="378" end_char="384">bayyana</TOKEN>
<TOKEN id="token-2-11" pos="NOUN" morph="ra始ayi:ra始ayi=NOUN" start_char="386" end_char="391">ra始ayi</TOKEN>
<TOKEN id="token-2-12" pos="CONSTRUCT" morph="na:na=CONSTRUCT" start_char="393" end_char="394">na</TOKEN>
<TOKEN id="token-2-13" pos="NOUN" morph="Twitter:twitter=NOUN" start_char="396" end_char="402">Twitter</TOKEN>
<TOKEN id="token-2-14" pos="punct" morph="none" start_char="403" end_char="403">,</TOKEN>
<TOKEN id="token-2-15" pos="ADV" morph="inda:inda=ADV" start_char="405" end_char="408">inda</TOKEN>
<TOKEN id="token-2-16" pos="NOUN" morph="wani:wani=NOUN" start_char="410" end_char="413">wani</TOKEN>
<TOKEN id="token-2-17" pos="PREP" morph="daga:daga=PREP" start_char="415" end_char="418">daga</TOKEN>
<TOKEN id="token-2-18" pos="PREP" morph="cikin:cikin=PREP" start_char="420" end_char="424">cikin</TOKEN>
<TOKEN id="token-2-19" pos="NOUN" morph="mabiya:mabiya=NOUN nsa:nsa=POSS_3SM" start_char="426" end_char="434">mabiyansa</TOKEN>
<TOKEN id="token-2-20" pos="punct" morph="none" start_char="436" end_char="436">(</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="unanalyzable" start_char="437" end_char="445">followers</TOKEN>
<TOKEN id="token-2-22" pos="punct" morph="none" start_char="446" end_char="446">)</TOKEN>
<TOKEN id="token-2-23" pos="VERB" morph="yayi:yayi=VERB" start_char="448" end_char="451">yayi</TOKEN>
<TOKEN id="token-2-24" pos="PRON" morph="masa:masa=PRON_BEN_3SM" start_char="453" end_char="456">masa</TOKEN>
<TOKEN id="token-2-25" pos="NOUN" morph="tambaya:tambaya=NOUN r:r=DEFINITE" start_char="458" end_char="465">tambayar</TOKEN>
<TOKEN id="token-2-26" pos="punct" morph="none" start_char="467" end_char="467">"</TOKEN>
<TOKEN id="token-2-27" pos="PARTICLE" morph="Shin:shin=PARTICLE" start_char="468" end_char="471">Shin</TOKEN>
<TOKEN id="token-2-28" pos="PRON" morph="yana:yana=PRON_WSP_3SM" start_char="473" end_char="476">yana</TOKEN>
<TOKEN id="token-2-29" pos="NOUN" morph="tunani:tunani=NOUN n:n=CONSTRUCT" start_char="478" end_char="484">tunanin</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="unanalyzable" start_char="486" end_char="491">abinda</TOKEN>
<TOKEN id="token-2-31" pos="PRON" morph="ya:ya=PRON_WSP_3SM" start_char="493" end_char="494">ya</TOKEN>
<TOKEN id="token-2-32" pos="VERB" morph="faru:faru=VERB" start_char="496" end_char="499">faru</TOKEN>
<TOKEN id="token-2-33" pos="PREP" morph="a:a=PREP" start_char="501" end_char="501">a</TOKEN>
<TOKEN id="token-2-34" pos="NOUN" morph="kasa:kasa=NOUN r:r=CONSTRUCT" start_char="503" end_char="507">kasar</TOKEN>
<TOKEN id="token-2-35" pos="NOUN" morph="Mali:mali=NOUN" start_char="509" end_char="512">Mali</TOKEN>
<TOKEN id="token-2-36" pos="PRON" morph="zai:zai=PRON_WSP_3SM" start_char="514" end_char="516">zai</TOKEN>
<TOKEN id="token-2-37" pos="VERB" morph="iya:iya=VERB" start_char="518" end_char="520">iya</TOKEN>
<TOKEN id="token-2-38" pos="VERB" morph="faruwa:faruwa=VERB" start_char="522" end_char="527">faruwa</TOKEN>
<TOKEN id="token-2-39" pos="PREP" morph="a:a=PREP" start_char="529" end_char="529">a</TOKEN>
<TOKEN id="token-2-40" pos="NOUN" morph="kasa:kasa=NOUN r:r=CONSTRUCT" start_char="531" end_char="535">kasar</TOKEN>
<TOKEN id="token-2-41" pos="ADV" morph="nan:nan=ADV" start_char="537" end_char="539">nan</TOKEN>
<TOKEN id="token-2-42" pos="COMP" morph="idan:idan=COMP" start_char="541" end_char="544">idan</TOKEN>
<TOKEN id="token-2-43" pos="NOUN" morph="shugabanni:shugabanni=NOUN" start_char="546" end_char="555">shugabanni</TOKEN>
<TOKEN id="token-2-44" pos="word" morph="unanalyzable" start_char="557" end_char="560">basu</TOKEN>
<TOKEN id="token-2-45" pos="VERB" morph="kula:kula=VERB" start_char="562" end_char="565">kula</TOKEN>
<TOKEN id="token-2-46" pos="PREP" morph="da:da=PREP" start_char="567" end_char="568">da</TOKEN>
<TOKEN id="token-2-47" pos="NOUN" morph="bukatu:bukatu=NOUN n:n=CONSTRUCT" start_char="570" end_char="576">bukatun</TOKEN>
<TOKEN id="token-2-48" pos="NOUN" morph="talakawa:talakawa=NOUN n:n=DEFINITE" start_char="578" end_char="586">talakawan</TOKEN>
<TOKEN id="token-2-49" pos="RELPRON" morph="da:da=RELPRON" start_char="588" end_char="589">da</TOKEN>
<TOKEN id="token-2-50" pos="PRON" morph="suka:suka=PRON_WSP_3P" start_char="591" end_char="594">suka</TOKEN>
<TOKEN id="token-2-51" pos="VERB" morph="zabe:zabe=VERB" start_char="596" end_char="599">zabe</TOKEN>
<TOKEN id="token-2-52" pos="PRON" morph="su:su=PRON_OBJ_3P" start_char="601" end_char="602">su</TOKEN>
<TOKEN id="token-2-53" pos="NEG" morph="ba:ba=NEG" start_char="604" end_char="605">ba</TOKEN>
<TOKEN id="token-2-54" pos="punct" morph="none" start_char="606" end_char="606">?</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
