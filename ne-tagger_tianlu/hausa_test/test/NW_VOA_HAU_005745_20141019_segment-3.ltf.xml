<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_VOA_HAU_005745_20141019_segment-3">
    <TEXT><SEG id="segment-3" start_char="463" end_char="575">
<ORIGINAL_TEXT>Goldring yace kasashen da suka kasa bada tallafi domin yaki d a cutar Ebola, suna kasar taimakawa hasarar rayuka.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="463" end_char="470">Goldring</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="472" end_char="475">yace</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="477" end_char="484">kasashen</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="486" end_char="487">da</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="489" end_char="492">suka</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="494" end_char="497">kasa</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="499" end_char="502">bada</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="504" end_char="510">tallafi</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="512" end_char="516">domin</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="518" end_char="521">yaki</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="523" end_char="523">d</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="525" end_char="525">a</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="527" end_char="531">cutar</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="533" end_char="537">Ebola</TOKEN>
<TOKEN id="token-3-14" pos="punct" morph="none" start_char="538" end_char="538">,</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="540" end_char="543">suna</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="545" end_char="549">kasar</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="551" end_char="559">taimakawa</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="561" end_char="567">hasarar</TOKEN>
<TOKEN id="token-3-19" pos="word" morph="none" start_char="569" end_char="574">rayuka</TOKEN>
<TOKEN id="token-3-20" pos="punct" morph="none" start_char="575" end_char="575">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
