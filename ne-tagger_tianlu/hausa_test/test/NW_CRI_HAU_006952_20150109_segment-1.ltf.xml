<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_CRI_HAU_006952_20150109_segment-1">
    <TEXT><SEG id="segment-1" start_char="177" end_char="292">
<ORIGINAL_TEXT>Shugaba Jonathan wanda ya bayyana takaicinsa ga aukuwar lamarin, ya ce, hakan tauye hakkin fadin albarkacin baki ne.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="177" end_char="183">Shugaba</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="185" end_char="192">Jonathan</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="194" end_char="198">wanda</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="200" end_char="201">ya</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="203" end_char="209">bayyana</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="211" end_char="220">takaicinsa</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="222" end_char="223">ga</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="225" end_char="231">aukuwar</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="233" end_char="239">lamarin</TOKEN>
<TOKEN id="token-1-9" pos="punct" morph="none" start_char="240" end_char="240">,</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="242" end_char="243">ya</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="245" end_char="246">ce</TOKEN>
<TOKEN id="token-1-12" pos="punct" morph="none" start_char="247" end_char="247">,</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="249" end_char="253">hakan</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="255" end_char="259">tauye</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="261" end_char="266">hakkin</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="268" end_char="272">fadin</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="274" end_char="283">albarkacin</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="285" end_char="288">baki</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="290" end_char="291">ne</TOKEN>
<TOKEN id="token-1-20" pos="punct" morph="none" start_char="292" end_char="292">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
