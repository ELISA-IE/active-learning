<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_CRI_HAU_006968_20150110_segment-0">
    <TEXT><SEG id="segment-0" start_char="0" end_char="180">
<ORIGINAL_TEXT>Shugaban kasar Faransa FranÃ§ois Hollande, ya ce kasar sa na ci gaba da fuskantar barazana, don haka ya zama wajibi a maida hankali wajen dakile duk wani yunkuri na kaiwa kasar hari.</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="0" end_char="7">Shugaban</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="9" end_char="13">kasar</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="15" end_char="21">Faransa</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="23" end_char="30">FranÃ§ois</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="32" end_char="39">Hollande</TOKEN>
<TOKEN id="token-0-5" pos="punct" morph="none" start_char="40" end_char="40">,</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="42" end_char="43">ya</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="45" end_char="46">ce</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="48" end_char="52">kasar</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="54" end_char="55">sa</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="57" end_char="58">na</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="60" end_char="61">ci</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="63" end_char="66">gaba</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="68" end_char="69">da</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="71" end_char="79">fuskantar</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="81" end_char="88">barazana</TOKEN>
<TOKEN id="token-0-16" pos="punct" morph="none" start_char="89" end_char="89">,</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="91" end_char="93">don</TOKEN>
<TOKEN id="token-0-18" pos="word" morph="none" start_char="95" end_char="98">haka</TOKEN>
<TOKEN id="token-0-19" pos="word" morph="none" start_char="100" end_char="101">ya</TOKEN>
<TOKEN id="token-0-20" pos="word" morph="none" start_char="103" end_char="106">zama</TOKEN>
<TOKEN id="token-0-21" pos="word" morph="none" start_char="108" end_char="113">wajibi</TOKEN>
<TOKEN id="token-0-22" pos="word" morph="none" start_char="115" end_char="115">a</TOKEN>
<TOKEN id="token-0-23" pos="word" morph="none" start_char="117" end_char="121">maida</TOKEN>
<TOKEN id="token-0-24" pos="word" morph="none" start_char="123" end_char="129">hankali</TOKEN>
<TOKEN id="token-0-25" pos="word" morph="none" start_char="131" end_char="135">wajen</TOKEN>
<TOKEN id="token-0-26" pos="word" morph="none" start_char="137" end_char="142">dakile</TOKEN>
<TOKEN id="token-0-27" pos="word" morph="none" start_char="144" end_char="146">duk</TOKEN>
<TOKEN id="token-0-28" pos="word" morph="none" start_char="148" end_char="151">wani</TOKEN>
<TOKEN id="token-0-29" pos="word" morph="none" start_char="153" end_char="159">yunkuri</TOKEN>
<TOKEN id="token-0-30" pos="word" morph="none" start_char="161" end_char="162">na</TOKEN>
<TOKEN id="token-0-31" pos="word" morph="none" start_char="164" end_char="168">kaiwa</TOKEN>
<TOKEN id="token-0-32" pos="word" morph="none" start_char="170" end_char="174">kasar</TOKEN>
<TOKEN id="token-0-33" pos="word" morph="none" start_char="176" end_char="179">hari</TOKEN>
<TOKEN id="token-0-34" pos="punct" morph="none" start_char="180" end_char="180">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
