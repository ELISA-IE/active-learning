<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_CRI_HAU_006319_20141117_segment-4">
    <TEXT><SEG id="segment-4" start_char="982" end_char="1285">
<ORIGINAL_TEXT>Mista Hong ya ci gaba da cewa, kasar Sin ce ta gina cibiyar, inda maÊ¼aikatan lafiyan Sin za su yi aiki a ciki, kuma bangaren Sin zai tafiyar da ita, lamarin da ya zuwa yanzu bai taba ganin irinsa a dukkan ayyukan da kasashen duniya suka yi domin taimakawa kasashen yammacin Afirka wajen yaki da cutar ba.</ORIGINAL_TEXT>
<TOKEN id="token-4-0" pos="word" morph="none" start_char="982" end_char="986">Mista</TOKEN>
<TOKEN id="token-4-1" pos="word" morph="none" start_char="988" end_char="991">Hong</TOKEN>
<TOKEN id="token-4-2" pos="word" morph="none" start_char="993" end_char="994">ya</TOKEN>
<TOKEN id="token-4-3" pos="word" morph="none" start_char="996" end_char="997">ci</TOKEN>
<TOKEN id="token-4-4" pos="word" morph="none" start_char="999" end_char="1002">gaba</TOKEN>
<TOKEN id="token-4-5" pos="word" morph="none" start_char="1004" end_char="1005">da</TOKEN>
<TOKEN id="token-4-6" pos="word" morph="none" start_char="1007" end_char="1010">cewa</TOKEN>
<TOKEN id="token-4-7" pos="punct" morph="none" start_char="1011" end_char="1011">,</TOKEN>
<TOKEN id="token-4-8" pos="word" morph="none" start_char="1013" end_char="1017">kasar</TOKEN>
<TOKEN id="token-4-9" pos="word" morph="none" start_char="1019" end_char="1021">Sin</TOKEN>
<TOKEN id="token-4-10" pos="word" morph="none" start_char="1023" end_char="1024">ce</TOKEN>
<TOKEN id="token-4-11" pos="word" morph="none" start_char="1026" end_char="1027">ta</TOKEN>
<TOKEN id="token-4-12" pos="word" morph="none" start_char="1029" end_char="1032">gina</TOKEN>
<TOKEN id="token-4-13" pos="word" morph="none" start_char="1034" end_char="1040">cibiyar</TOKEN>
<TOKEN id="token-4-14" pos="punct" morph="none" start_char="1041" end_char="1041">,</TOKEN>
<TOKEN id="token-4-15" pos="word" morph="none" start_char="1043" end_char="1046">inda</TOKEN>
<TOKEN id="token-4-16" pos="word" morph="none" start_char="1048" end_char="1057">maÊ¼aikatan</TOKEN>
<TOKEN id="token-4-17" pos="word" morph="none" start_char="1059" end_char="1065">lafiyan</TOKEN>
<TOKEN id="token-4-18" pos="word" morph="none" start_char="1067" end_char="1069">Sin</TOKEN>
<TOKEN id="token-4-19" pos="word" morph="none" start_char="1071" end_char="1072">za</TOKEN>
<TOKEN id="token-4-20" pos="word" morph="none" start_char="1074" end_char="1075">su</TOKEN>
<TOKEN id="token-4-21" pos="word" morph="none" start_char="1077" end_char="1078">yi</TOKEN>
<TOKEN id="token-4-22" pos="word" morph="none" start_char="1080" end_char="1083">aiki</TOKEN>
<TOKEN id="token-4-23" pos="word" morph="none" start_char="1085" end_char="1085">a</TOKEN>
<TOKEN id="token-4-24" pos="word" morph="none" start_char="1087" end_char="1090">ciki</TOKEN>
<TOKEN id="token-4-25" pos="punct" morph="none" start_char="1091" end_char="1091">,</TOKEN>
<TOKEN id="token-4-26" pos="word" morph="none" start_char="1093" end_char="1096">kuma</TOKEN>
<TOKEN id="token-4-27" pos="word" morph="none" start_char="1098" end_char="1105">bangaren</TOKEN>
<TOKEN id="token-4-28" pos="word" morph="none" start_char="1107" end_char="1109">Sin</TOKEN>
<TOKEN id="token-4-29" pos="word" morph="none" start_char="1111" end_char="1113">zai</TOKEN>
<TOKEN id="token-4-30" pos="word" morph="none" start_char="1115" end_char="1121">tafiyar</TOKEN>
<TOKEN id="token-4-31" pos="word" morph="none" start_char="1123" end_char="1124">da</TOKEN>
<TOKEN id="token-4-32" pos="word" morph="none" start_char="1126" end_char="1128">ita</TOKEN>
<TOKEN id="token-4-33" pos="punct" morph="none" start_char="1129" end_char="1129">,</TOKEN>
<TOKEN id="token-4-34" pos="word" morph="none" start_char="1131" end_char="1137">lamarin</TOKEN>
<TOKEN id="token-4-35" pos="word" morph="none" start_char="1139" end_char="1140">da</TOKEN>
<TOKEN id="token-4-36" pos="word" morph="none" start_char="1142" end_char="1143">ya</TOKEN>
<TOKEN id="token-4-37" pos="word" morph="none" start_char="1145" end_char="1148">zuwa</TOKEN>
<TOKEN id="token-4-38" pos="word" morph="none" start_char="1150" end_char="1154">yanzu</TOKEN>
<TOKEN id="token-4-39" pos="word" morph="none" start_char="1156" end_char="1158">bai</TOKEN>
<TOKEN id="token-4-40" pos="word" morph="none" start_char="1160" end_char="1163">taba</TOKEN>
<TOKEN id="token-4-41" pos="word" morph="none" start_char="1165" end_char="1169">ganin</TOKEN>
<TOKEN id="token-4-42" pos="word" morph="none" start_char="1171" end_char="1176">irinsa</TOKEN>
<TOKEN id="token-4-43" pos="word" morph="none" start_char="1178" end_char="1178">a</TOKEN>
<TOKEN id="token-4-44" pos="word" morph="none" start_char="1180" end_char="1185">dukkan</TOKEN>
<TOKEN id="token-4-45" pos="word" morph="none" start_char="1187" end_char="1193">ayyukan</TOKEN>
<TOKEN id="token-4-46" pos="word" morph="none" start_char="1195" end_char="1196">da</TOKEN>
<TOKEN id="token-4-47" pos="word" morph="none" start_char="1198" end_char="1205">kasashen</TOKEN>
<TOKEN id="token-4-48" pos="word" morph="none" start_char="1207" end_char="1212">duniya</TOKEN>
<TOKEN id="token-4-49" pos="word" morph="none" start_char="1214" end_char="1217">suka</TOKEN>
<TOKEN id="token-4-50" pos="word" morph="none" start_char="1219" end_char="1220">yi</TOKEN>
<TOKEN id="token-4-51" pos="word" morph="none" start_char="1222" end_char="1226">domin</TOKEN>
<TOKEN id="token-4-52" pos="word" morph="none" start_char="1228" end_char="1236">taimakawa</TOKEN>
<TOKEN id="token-4-53" pos="word" morph="none" start_char="1238" end_char="1245">kasashen</TOKEN>
<TOKEN id="token-4-54" pos="word" morph="none" start_char="1247" end_char="1254">yammacin</TOKEN>
<TOKEN id="token-4-55" pos="word" morph="none" start_char="1256" end_char="1261">Afirka</TOKEN>
<TOKEN id="token-4-56" pos="word" morph="none" start_char="1263" end_char="1267">wajen</TOKEN>
<TOKEN id="token-4-57" pos="word" morph="none" start_char="1269" end_char="1272">yaki</TOKEN>
<TOKEN id="token-4-58" pos="word" morph="none" start_char="1274" end_char="1275">da</TOKEN>
<TOKEN id="token-4-59" pos="word" morph="none" start_char="1277" end_char="1281">cutar</TOKEN>
<TOKEN id="token-4-60" pos="word" morph="none" start_char="1283" end_char="1284">ba</TOKEN>
<TOKEN id="token-4-61" pos="punct" morph="none" start_char="1285" end_char="1285">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
