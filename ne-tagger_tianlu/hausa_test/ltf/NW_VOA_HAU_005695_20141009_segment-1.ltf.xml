<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_VOA_HAU_005695_20141009_segment-1">
    <TEXT><SEG id="segment-1" start_char="17" end_char="228">
<ORIGINAL_TEXT>Kakakin rundunar tsaron a jihar Filato Keften Ikedichi Iweha yace tun can dama suna sa ido akan mutanen da ta cafke kuma tuni ta mikasu ga hukumar shige da fice domin su cigaba da daukan matakan da suka kamakata.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="17" end_char="23">Kakakin</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="25" end_char="32">rundunar</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="34" end_char="39">tsaron</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="41" end_char="41">a</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="43" end_char="47">jihar</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="49" end_char="54">Filato</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="56" end_char="61">Keften</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="63" end_char="70">Ikedichi</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="72" end_char="76">Iweha</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="78" end_char="81">yace</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="83" end_char="85">tun</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="87" end_char="89">can</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="91" end_char="94">dama</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="96" end_char="99">suna</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="101" end_char="102">sa</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="104" end_char="106">ido</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="108" end_char="111">akan</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="113" end_char="119">mutanen</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="121" end_char="122">da</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="124" end_char="125">ta</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="127" end_char="131">cafke</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="133" end_char="136">kuma</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="138" end_char="141">tuni</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="143" end_char="144">ta</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="146" end_char="151">mikasu</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="153" end_char="154">ga</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="156" end_char="162">hukumar</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="164" end_char="168">shige</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="170" end_char="171">da</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="173" end_char="176">fice</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="178" end_char="182">domin</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="184" end_char="185">su</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="187" end_char="192">cigaba</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="194" end_char="195">da</TOKEN>
<TOKEN id="token-1-34" pos="word" morph="none" start_char="197" end_char="202">daukan</TOKEN>
<TOKEN id="token-1-35" pos="word" morph="none" start_char="204" end_char="210">matakan</TOKEN>
<TOKEN id="token-1-36" pos="word" morph="none" start_char="212" end_char="213">da</TOKEN>
<TOKEN id="token-1-37" pos="word" morph="none" start_char="215" end_char="218">suka</TOKEN>
<TOKEN id="token-1-38" pos="word" morph="none" start_char="220" end_char="227">kamakata</TOKEN>
<TOKEN id="token-1-39" pos="punct" morph="none" start_char="228" end_char="228">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
