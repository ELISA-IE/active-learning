<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="WL_NUR_HAU_007874_20100705_segment-10">
    <TEXT><SEG id="segment-10" start_char="2084" end_char="2386">
<ORIGINAL_TEXT>A watan Mayun wannan shekara ta 2009 ne dai mahukuntan kasar Gabon din suka sanar cewa shugaban ya tafi kasar Spain don shakatawa da kuma gudanar da zaman makokin matarsa da ta rasu, to sai dai wasu kafafen watsa labaran sun ce rashin lafiya ne ta kai shi kasar Spain din inda yake fama da cutar cancer.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="2084" end_char="2084">A</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="2086" end_char="2090">watan</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="2092" end_char="2096">Mayun</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="2098" end_char="2103">wannan</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="2105" end_char="2111">shekara</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="2113" end_char="2114">ta</TOKEN>
<TOKEN id="token-10-6" pos="number" morph="none" start_char="2116" end_char="2119">2009</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="2121" end_char="2122">ne</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="2124" end_char="2126">dai</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="2128" end_char="2137">mahukuntan</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="2139" end_char="2143">kasar</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="2145" end_char="2149">Gabon</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="2151" end_char="2153">din</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="2155" end_char="2158">suka</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="2160" end_char="2164">sanar</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="2166" end_char="2169">cewa</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="2171" end_char="2178">shugaban</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="2180" end_char="2181">ya</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="2183" end_char="2186">tafi</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="2188" end_char="2192">kasar</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="2194" end_char="2198">Spain</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="2200" end_char="2202">don</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="2204" end_char="2212">shakatawa</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="2214" end_char="2215">da</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="2217" end_char="2220">kuma</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="2222" end_char="2228">gudanar</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="2230" end_char="2231">da</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="2233" end_char="2237">zaman</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="2239" end_char="2245">makokin</TOKEN>
<TOKEN id="token-10-29" pos="word" morph="none" start_char="2247" end_char="2253">matarsa</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="2255" end_char="2256">da</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="2258" end_char="2259">ta</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="2261" end_char="2264">rasu</TOKEN>
<TOKEN id="token-10-33" pos="punct" morph="none" start_char="2265" end_char="2265">,</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="2267" end_char="2268">to</TOKEN>
<TOKEN id="token-10-35" pos="word" morph="none" start_char="2270" end_char="2272">sai</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="2274" end_char="2276">dai</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="2278" end_char="2281">wasu</TOKEN>
<TOKEN id="token-10-38" pos="word" morph="none" start_char="2283" end_char="2289">kafafen</TOKEN>
<TOKEN id="token-10-39" pos="word" morph="none" start_char="2291" end_char="2295">watsa</TOKEN>
<TOKEN id="token-10-40" pos="word" morph="none" start_char="2297" end_char="2303">labaran</TOKEN>
<TOKEN id="token-10-41" pos="word" morph="none" start_char="2305" end_char="2307">sun</TOKEN>
<TOKEN id="token-10-42" pos="word" morph="none" start_char="2309" end_char="2310">ce</TOKEN>
<TOKEN id="token-10-43" pos="word" morph="none" start_char="2312" end_char="2317">rashin</TOKEN>
<TOKEN id="token-10-44" pos="word" morph="none" start_char="2319" end_char="2324">lafiya</TOKEN>
<TOKEN id="token-10-45" pos="word" morph="none" start_char="2326" end_char="2327">ne</TOKEN>
<TOKEN id="token-10-46" pos="word" morph="none" start_char="2329" end_char="2330">ta</TOKEN>
<TOKEN id="token-10-47" pos="word" morph="none" start_char="2332" end_char="2334">kai</TOKEN>
<TOKEN id="token-10-48" pos="word" morph="none" start_char="2336" end_char="2338">shi</TOKEN>
<TOKEN id="token-10-49" pos="word" morph="none" start_char="2340" end_char="2344">kasar</TOKEN>
<TOKEN id="token-10-50" pos="word" morph="none" start_char="2346" end_char="2350">Spain</TOKEN>
<TOKEN id="token-10-51" pos="word" morph="none" start_char="2352" end_char="2354">din</TOKEN>
<TOKEN id="token-10-52" pos="word" morph="none" start_char="2356" end_char="2359">inda</TOKEN>
<TOKEN id="token-10-53" pos="word" morph="none" start_char="2361" end_char="2364">yake</TOKEN>
<TOKEN id="token-10-54" pos="word" morph="none" start_char="2366" end_char="2369">fama</TOKEN>
<TOKEN id="token-10-55" pos="word" morph="none" start_char="2371" end_char="2372">da</TOKEN>
<TOKEN id="token-10-56" pos="word" morph="none" start_char="2374" end_char="2378">cutar</TOKEN>
<TOKEN id="token-10-57" pos="word" morph="none" start_char="2380" end_char="2385">cancer</TOKEN>
<TOKEN id="token-10-58" pos="punct" morph="none" start_char="2386" end_char="2386">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
