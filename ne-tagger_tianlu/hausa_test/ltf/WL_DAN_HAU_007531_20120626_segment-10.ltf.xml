<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="WL_DAN_HAU_007531_20120626_segment-10">
    <TEXT><SEG id="segment-10" start_char="2810" end_char="2996">
<ORIGINAL_TEXT>A karshe ba abin da zance sai godiya ga 始yan uwa da suka taya mu da addu始a, musamman wadanda suka yi ta kirana a waya suna tambayar lafiyata, Allah ya saka da alheri, ya kuma bar zumunci.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="2810" end_char="2810">A</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="2812" end_char="2817">karshe</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="2819" end_char="2820">ba</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="2822" end_char="2825">abin</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="2827" end_char="2828">da</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="2830" end_char="2834">zance</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="2836" end_char="2838">sai</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="2840" end_char="2845">godiya</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="2847" end_char="2848">ga</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="2850" end_char="2853">始yan</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="2855" end_char="2857">uwa</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="2859" end_char="2860">da</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="2862" end_char="2865">suka</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="2867" end_char="2870">taya</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="2872" end_char="2873">mu</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="2875" end_char="2876">da</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="2878" end_char="2883">addu始a</TOKEN>
<TOKEN id="token-10-17" pos="punct" morph="none" start_char="2884" end_char="2884">,</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="2886" end_char="2893">musamman</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="2895" end_char="2901">wadanda</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="2903" end_char="2906">suka</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="2908" end_char="2909">yi</TOKEN>
<TOKEN id="token-10-22" pos="word" morph="none" start_char="2911" end_char="2912">ta</TOKEN>
<TOKEN id="token-10-23" pos="word" morph="none" start_char="2914" end_char="2919">kirana</TOKEN>
<TOKEN id="token-10-24" pos="word" morph="none" start_char="2921" end_char="2921">a</TOKEN>
<TOKEN id="token-10-25" pos="word" morph="none" start_char="2923" end_char="2926">waya</TOKEN>
<TOKEN id="token-10-26" pos="word" morph="none" start_char="2928" end_char="2931">suna</TOKEN>
<TOKEN id="token-10-27" pos="word" morph="none" start_char="2933" end_char="2940">tambayar</TOKEN>
<TOKEN id="token-10-28" pos="word" morph="none" start_char="2942" end_char="2949">lafiyata</TOKEN>
<TOKEN id="token-10-29" pos="punct" morph="none" start_char="2950" end_char="2950">,</TOKEN>
<TOKEN id="token-10-30" pos="word" morph="none" start_char="2952" end_char="2956">Allah</TOKEN>
<TOKEN id="token-10-31" pos="word" morph="none" start_char="2958" end_char="2959">ya</TOKEN>
<TOKEN id="token-10-32" pos="word" morph="none" start_char="2961" end_char="2964">saka</TOKEN>
<TOKEN id="token-10-33" pos="word" morph="none" start_char="2966" end_char="2967">da</TOKEN>
<TOKEN id="token-10-34" pos="word" morph="none" start_char="2969" end_char="2974">alheri</TOKEN>
<TOKEN id="token-10-35" pos="punct" morph="none" start_char="2975" end_char="2975">,</TOKEN>
<TOKEN id="token-10-36" pos="word" morph="none" start_char="2977" end_char="2978">ya</TOKEN>
<TOKEN id="token-10-37" pos="word" morph="none" start_char="2980" end_char="2983">kuma</TOKEN>
<TOKEN id="token-10-38" pos="word" morph="none" start_char="2985" end_char="2987">bar</TOKEN>
<TOKEN id="token-10-39" pos="word" morph="none" start_char="2989" end_char="2995">zumunci</TOKEN>
<TOKEN id="token-10-40" pos="punct" morph="none" start_char="2996" end_char="2996">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
