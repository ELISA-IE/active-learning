<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="WL_ALM_HAU_006206_20100321_segment-30">
    <TEXT><SEG id="segment-30" start_char="2828" end_char="2936">
<ORIGINAL_TEXT>Shin akwai wata hanya da zaʼa ragewa wadanda irin wannan masifa ta afkawa radadi wato ta hanyar basu tallafi?</ORIGINAL_TEXT>
<TOKEN id="token-30-0" pos="word" morph="none" start_char="2828" end_char="2831">Shin</TOKEN>
<TOKEN id="token-30-1" pos="word" morph="none" start_char="2833" end_char="2837">akwai</TOKEN>
<TOKEN id="token-30-2" pos="word" morph="none" start_char="2839" end_char="2842">wata</TOKEN>
<TOKEN id="token-30-3" pos="word" morph="none" start_char="2844" end_char="2848">hanya</TOKEN>
<TOKEN id="token-30-4" pos="word" morph="none" start_char="2850" end_char="2851">da</TOKEN>
<TOKEN id="token-30-5" pos="word" morph="none" start_char="2853" end_char="2856">zaʼa</TOKEN>
<TOKEN id="token-30-6" pos="word" morph="none" start_char="2858" end_char="2863">ragewa</TOKEN>
<TOKEN id="token-30-7" pos="word" morph="none" start_char="2865" end_char="2871">wadanda</TOKEN>
<TOKEN id="token-30-8" pos="word" morph="none" start_char="2873" end_char="2876">irin</TOKEN>
<TOKEN id="token-30-9" pos="word" morph="none" start_char="2878" end_char="2883">wannan</TOKEN>
<TOKEN id="token-30-10" pos="word" morph="none" start_char="2885" end_char="2890">masifa</TOKEN>
<TOKEN id="token-30-11" pos="word" morph="none" start_char="2892" end_char="2893">ta</TOKEN>
<TOKEN id="token-30-12" pos="word" morph="none" start_char="2895" end_char="2900">afkawa</TOKEN>
<TOKEN id="token-30-13" pos="word" morph="none" start_char="2902" end_char="2907">radadi</TOKEN>
<TOKEN id="token-30-14" pos="word" morph="none" start_char="2909" end_char="2912">wato</TOKEN>
<TOKEN id="token-30-15" pos="word" morph="none" start_char="2914" end_char="2915">ta</TOKEN>
<TOKEN id="token-30-16" pos="word" morph="none" start_char="2917" end_char="2922">hanyar</TOKEN>
<TOKEN id="token-30-17" pos="word" morph="none" start_char="2924" end_char="2927">basu</TOKEN>
<TOKEN id="token-30-18" pos="word" morph="none" start_char="2929" end_char="2935">tallafi</TOKEN>
<TOKEN id="token-30-19" pos="punct" morph="none" start_char="2936" end_char="2936">?</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
