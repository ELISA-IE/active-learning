<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_VOA_HAU_005040_20140609_segment-1">
    <TEXT><SEG id="segment-1" start_char="276" end_char="425">
<ORIGINAL_TEXT>Tun lokacin da gwamnatin Jonathan ta sabunta dokar ta baci kungiyar Boko Haram ta kara kaimi akan hare-haren da take kaiwa a jihohin dake cikin dokar.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="276" end_char="278">Tun</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="280" end_char="286">lokacin</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="288" end_char="289">da</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="291" end_char="299">gwamnatin</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="301" end_char="308">Jonathan</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="310" end_char="311">ta</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="313" end_char="319">sabunta</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="321" end_char="325">dokar</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="327" end_char="328">ta</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="330" end_char="333">baci</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="335" end_char="342">kungiyar</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="344" end_char="347">Boko</TOKEN>
<TOKEN id="token-1-12" pos="word" morph="none" start_char="349" end_char="353">Haram</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="355" end_char="356">ta</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="358" end_char="361">kara</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="363" end_char="367">kaimi</TOKEN>
<TOKEN id="token-1-16" pos="word" morph="none" start_char="369" end_char="372">akan</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="374" end_char="377">hare</TOKEN>
<TOKEN id="token-1-18" pos="punct" morph="none" start_char="378" end_char="378">-</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="379" end_char="383">haren</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="385" end_char="386">da</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="388" end_char="391">take</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="393" end_char="397">kaiwa</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="399" end_char="399">a</TOKEN>
<TOKEN id="token-1-24" pos="word" morph="none" start_char="401" end_char="407">jihohin</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="409" end_char="412">dake</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="414" end_char="418">cikin</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="420" end_char="424">dokar</TOKEN>
<TOKEN id="token-1-28" pos="punct" morph="none" start_char="425" end_char="425">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
