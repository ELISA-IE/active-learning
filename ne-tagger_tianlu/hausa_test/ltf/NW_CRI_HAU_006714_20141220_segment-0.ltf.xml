<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_CRI_HAU_006714_20141220_segment-0">
    <TEXT><SEG id="segment-0" start_char="0" end_char="194">
<ORIGINAL_TEXT>Wakilin dindindin na kasar Sin a MDD Liu Jieyi, ya ce akwai bukatar kasashen duniya su dauki matakan bai daya, tare da kaucewa nuna banbanci, ko wariya a yakin da ake ci gaba da yi da taÊ¼addanci.</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="0" end_char="6">Wakilin</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="8" end_char="16">dindindin</TOKEN>
<TOKEN id="token-0-2" pos="word" morph="none" start_char="18" end_char="19">na</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="21" end_char="25">kasar</TOKEN>
<TOKEN id="token-0-4" pos="word" morph="none" start_char="27" end_char="29">Sin</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="31" end_char="31">a</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="33" end_char="35">MDD</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="37" end_char="39">Liu</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="41" end_char="45">Jieyi</TOKEN>
<TOKEN id="token-0-9" pos="punct" morph="none" start_char="46" end_char="46">,</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="48" end_char="49">ya</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="51" end_char="52">ce</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="54" end_char="58">akwai</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="60" end_char="66">bukatar</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="68" end_char="75">kasashen</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="77" end_char="82">duniya</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="84" end_char="85">su</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="87" end_char="91">dauki</TOKEN>
<TOKEN id="token-0-18" pos="word" morph="none" start_char="93" end_char="99">matakan</TOKEN>
<TOKEN id="token-0-19" pos="word" morph="none" start_char="101" end_char="103">bai</TOKEN>
<TOKEN id="token-0-20" pos="word" morph="none" start_char="105" end_char="108">daya</TOKEN>
<TOKEN id="token-0-21" pos="punct" morph="none" start_char="109" end_char="109">,</TOKEN>
<TOKEN id="token-0-22" pos="word" morph="none" start_char="111" end_char="114">tare</TOKEN>
<TOKEN id="token-0-23" pos="word" morph="none" start_char="116" end_char="117">da</TOKEN>
<TOKEN id="token-0-24" pos="word" morph="none" start_char="119" end_char="125">kaucewa</TOKEN>
<TOKEN id="token-0-25" pos="word" morph="none" start_char="127" end_char="130">nuna</TOKEN>
<TOKEN id="token-0-26" pos="word" morph="none" start_char="132" end_char="139">banbanci</TOKEN>
<TOKEN id="token-0-27" pos="punct" morph="none" start_char="140" end_char="140">,</TOKEN>
<TOKEN id="token-0-28" pos="word" morph="none" start_char="142" end_char="143">ko</TOKEN>
<TOKEN id="token-0-29" pos="word" morph="none" start_char="145" end_char="150">wariya</TOKEN>
<TOKEN id="token-0-30" pos="word" morph="none" start_char="152" end_char="152">a</TOKEN>
<TOKEN id="token-0-31" pos="word" morph="none" start_char="154" end_char="158">yakin</TOKEN>
<TOKEN id="token-0-32" pos="word" morph="none" start_char="160" end_char="161">da</TOKEN>
<TOKEN id="token-0-33" pos="word" morph="none" start_char="163" end_char="165">ake</TOKEN>
<TOKEN id="token-0-34" pos="word" morph="none" start_char="167" end_char="168">ci</TOKEN>
<TOKEN id="token-0-35" pos="word" morph="none" start_char="170" end_char="173">gaba</TOKEN>
<TOKEN id="token-0-36" pos="word" morph="none" start_char="175" end_char="176">da</TOKEN>
<TOKEN id="token-0-37" pos="word" morph="none" start_char="178" end_char="179">yi</TOKEN>
<TOKEN id="token-0-38" pos="word" morph="none" start_char="181" end_char="182">da</TOKEN>
<TOKEN id="token-0-39" pos="word" morph="none" start_char="184" end_char="193">taÊ¼addanci</TOKEN>
<TOKEN id="token-0-40" pos="punct" morph="none" start_char="194" end_char="194">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
