<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="WL_ALM_HAU_006203_20100228_segment-35">
    <TEXT><SEG id="segment-35" start_char="4479" end_char="4594">
<ORIGINAL_TEXT>Hakkin wanene ya tabbatar da cewa hukumomi sun cika aikin su na kare hakkin jamaÊ¼a, tare da sauke nauyin dake kansu?</ORIGINAL_TEXT>
<TOKEN id="token-35-0" pos="word" morph="none" start_char="4479" end_char="4484">Hakkin</TOKEN>
<TOKEN id="token-35-1" pos="word" morph="none" start_char="4486" end_char="4491">wanene</TOKEN>
<TOKEN id="token-35-2" pos="word" morph="none" start_char="4493" end_char="4494">ya</TOKEN>
<TOKEN id="token-35-3" pos="word" morph="none" start_char="4496" end_char="4503">tabbatar</TOKEN>
<TOKEN id="token-35-4" pos="word" morph="none" start_char="4505" end_char="4506">da</TOKEN>
<TOKEN id="token-35-5" pos="word" morph="none" start_char="4508" end_char="4511">cewa</TOKEN>
<TOKEN id="token-35-6" pos="word" morph="none" start_char="4513" end_char="4520">hukumomi</TOKEN>
<TOKEN id="token-35-7" pos="word" morph="none" start_char="4522" end_char="4524">sun</TOKEN>
<TOKEN id="token-35-8" pos="word" morph="none" start_char="4526" end_char="4529">cika</TOKEN>
<TOKEN id="token-35-9" pos="word" morph="none" start_char="4531" end_char="4535">aikin</TOKEN>
<TOKEN id="token-35-10" pos="word" morph="none" start_char="4537" end_char="4538">su</TOKEN>
<TOKEN id="token-35-11" pos="word" morph="none" start_char="4540" end_char="4541">na</TOKEN>
<TOKEN id="token-35-12" pos="word" morph="none" start_char="4543" end_char="4546">kare</TOKEN>
<TOKEN id="token-35-13" pos="word" morph="none" start_char="4548" end_char="4553">hakkin</TOKEN>
<TOKEN id="token-35-14" pos="word" morph="none" start_char="4555" end_char="4560">jamaÊ¼a</TOKEN>
<TOKEN id="token-35-15" pos="punct" morph="none" start_char="4561" end_char="4561">,</TOKEN>
<TOKEN id="token-35-16" pos="word" morph="none" start_char="4563" end_char="4566">tare</TOKEN>
<TOKEN id="token-35-17" pos="word" morph="none" start_char="4568" end_char="4569">da</TOKEN>
<TOKEN id="token-35-18" pos="word" morph="none" start_char="4571" end_char="4575">sauke</TOKEN>
<TOKEN id="token-35-19" pos="word" morph="none" start_char="4577" end_char="4582">nauyin</TOKEN>
<TOKEN id="token-35-20" pos="word" morph="none" start_char="4584" end_char="4587">dake</TOKEN>
<TOKEN id="token-35-21" pos="word" morph="none" start_char="4589" end_char="4593">kansu</TOKEN>
<TOKEN id="token-35-22" pos="punct" morph="none" start_char="4594" end_char="4594">?</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
