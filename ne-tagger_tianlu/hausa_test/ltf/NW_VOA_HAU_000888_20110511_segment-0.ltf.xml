<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_VOA_HAU_000888_20110511_segment-0">
    <TEXT><SEG id="segment-0" start_char="0" end_char="310">
<ORIGINAL_TEXT>Hukumar samar da abinci da aikin gona ta Majalisar Dinkin Duniya tayi gargadin cewa wajibi ne Gwamnatocin kasashen nahiyar Asiya su gaggauta daukan matakan hana tashin farashin kayan abinchi da yanzu haka ke neman afkawa kasashen na Asiya,domin hana afkuwar irin abinda ya faru a shekarar 2008 da shekarar 2009.</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="NOUN" morph="Hukumar:hukumar=NOUN" start_char="0" end_char="6">Hukumar</TOKEN>
<TOKEN id="token-0-1" pos="NOUN" morph="sama:sama=NOUN r:r=CONSTRUCT" start_char="8" end_char="12">samar</TOKEN>
<TOKEN id="token-0-2" pos="PREP" morph="da:da=PREP" start_char="14" end_char="15">da</TOKEN>
<TOKEN id="token-0-3" pos="NOUN" morph="abinci:abinci=NOUN" start_char="17" end_char="22">abinci</TOKEN>
<TOKEN id="token-0-4" pos="CONJ" morph="da:da=CONJ" start_char="24" end_char="25">da</TOKEN>
<TOKEN id="token-0-5" pos="NOUN" morph="aiki:aiki=NOUN n:n=CONSTRUCT" start_char="27" end_char="31">aikin</TOKEN>
<TOKEN id="token-0-6" pos="NOUN" morph="gona:gona=NOUN" start_char="33" end_char="36">gona</TOKEN>
<TOKEN id="token-0-7" pos="CONSTRUCT" morph="ta:ta=CONSTRUCT" start_char="38" end_char="39">ta</TOKEN>
<TOKEN id="token-0-8" pos="NOUN" morph="Majalisa:majalisa=NOUN r:r=CONSTRUCT" start_char="41" end_char="49">Majalisar</TOKEN>
<TOKEN id="token-0-9" pos="NOUN" morph="Dinkin:dinkin=NOUN" start_char="51" end_char="56">Dinkin</TOKEN>
<TOKEN id="token-0-10" pos="NOUN" morph="Duniya:duniya=NOUN" start_char="58" end_char="63">Duniya</TOKEN>
<TOKEN id="token-0-11" pos="VERB" morph="tayi:tayi=VERB" start_char="65" end_char="68">tayi</TOKEN>
<TOKEN id="token-0-12" pos="VERB" morph="gargadin:gargadin=VERB" start_char="70" end_char="77">gargadin</TOKEN>
<TOKEN id="token-0-13" pos="NOUN" morph="cewa:cewa=NOUN" start_char="79" end_char="82">cewa</TOKEN>
<TOKEN id="token-0-14" pos="NOUN" morph="wajibi:wajibi=NOUN" start_char="84" end_char="89">wajibi</TOKEN>
<TOKEN id="token-0-15" pos="COPULA" morph="ne:ne=COPULA" start_char="91" end_char="92">ne</TOKEN>
<TOKEN id="token-0-16" pos="NOUN" morph="Gwamnatoci:gwamnatoci=NOUN n:n=CONSTRUCT" start_char="94" end_char="104">Gwamnatocin</TOKEN>
<TOKEN id="token-0-17" pos="NOUN" morph="kasashe:kasashe=NOUN n:n=CONSTRUCT" start_char="106" end_char="113">kasashen</TOKEN>
<TOKEN id="token-0-18" pos="NOUN" morph="nahiya:nahiya=NOUN r:r=CONSTRUCT" start_char="115" end_char="121">nahiyar</TOKEN>
<TOKEN id="token-0-19" pos="NOUN" morph="Asiya:asiya=NOUN" start_char="123" end_char="127">Asiya</TOKEN>
<TOKEN id="token-0-20" pos="PRON" morph="su:su=PRON_WSP_3P" start_char="129" end_char="130">su</TOKEN>
<TOKEN id="token-0-21" pos="VERB" morph="gaggauta:gaggauta=VERB" start_char="132" end_char="139">gaggauta</TOKEN>
<TOKEN id="token-0-22" pos="VERB" morph="daukan:daukan=VERB" start_char="141" end_char="146">daukan</TOKEN>
<TOKEN id="token-0-23" pos="NOUN" morph="mataka:mataka=NOUN n:n=CONSTRUCT" start_char="148" end_char="154">matakan</TOKEN>
<TOKEN id="token-0-24" pos="VERB" morph="hana:hana=VERB" start_char="156" end_char="159">hana</TOKEN>
<TOKEN id="token-0-25" pos="NOUN" morph="tashi:tashi=NOUN n:n=CONSTRUCT" start_char="161" end_char="166">tashin</TOKEN>
<TOKEN id="token-0-26" pos="NOUN" morph="farashi:farashi=NOUN n:n=CONSTRUCT" start_char="168" end_char="175">farashin</TOKEN>
<TOKEN id="token-0-27" pos="NOUN" morph="kaya:kaya=NOUN n:n=CONSTRUCT" start_char="177" end_char="181">kayan</TOKEN>
<TOKEN id="token-0-28" pos="NOUN" morph="abinchi:abinchi=NOUN" start_char="183" end_char="189">abinchi</TOKEN>
<TOKEN id="token-0-29" pos="RELPRON" morph="da:da=RELPRON" start_char="191" end_char="192">da</TOKEN>
<TOKEN id="token-0-30" pos="ADV" morph="yanzu:yanzu=ADV" start_char="194" end_char="198">yanzu</TOKEN>
<TOKEN id="token-0-31" pos="ADV" morph="haka:haka=ADV" start_char="200" end_char="203">haka</TOKEN>
<TOKEN id="token-0-32" pos="PRON" morph="ke:ke=CONT" start_char="205" end_char="206">ke</TOKEN>
<TOKEN id="token-0-33" pos="NOUN" morph="nema:nema=NOUN n:n=CONSTRUCT" start_char="208" end_char="212">neman</TOKEN>
<TOKEN id="token-0-34" pos="VERB" morph="afkawa:afkawa=VERB" start_char="214" end_char="219">afkawa</TOKEN>
<TOKEN id="token-0-35" pos="NOUN" morph="kasashe:kasashe=NOUN n:n=DEFINITE" start_char="221" end_char="228">kasashen</TOKEN>
<TOKEN id="token-0-36" pos="CONSTRUCT" morph="na:na=CONSTRUCT" start_char="230" end_char="231">na</TOKEN>
<TOKEN id="token-0-37" pos="NOUN" morph="Asiya:asiya=NOUN" start_char="233" end_char="237">Asiya</TOKEN>
<TOKEN id="token-0-38" pos="punct" morph="none" start_char="238" end_char="238">,</TOKEN>
<TOKEN id="token-0-39" pos="PREP" morph="domin:domin=PREP" start_char="239" end_char="243">domin</TOKEN>
<TOKEN id="token-0-40" pos="VERB" morph="hana:hana=VERB" start_char="245" end_char="248">hana</TOKEN>
<TOKEN id="token-0-41" pos="NOUN" morph="afkuwa:afkuwa=NOUN r:r=CONSTRUCT" start_char="250" end_char="256">afkuwar</TOKEN>
<TOKEN id="token-0-42" pos="PREP" morph="irin:irin=PREP" start_char="258" end_char="261">irin</TOKEN>
<TOKEN id="token-0-43" pos="NOUN" morph="abinda:abinda=NOUN" start_char="263" end_char="268">abinda</TOKEN>
<TOKEN id="token-0-44" pos="PRON" morph="ya:ya=PRON_WSP_3SM" start_char="270" end_char="271">ya</TOKEN>
<TOKEN id="token-0-45" pos="VERB" morph="faru:faru=VERB" start_char="273" end_char="276">faru</TOKEN>
<TOKEN id="token-0-46" pos="PREP" morph="a:a=PREP" start_char="278" end_char="278">a</TOKEN>
<TOKEN id="token-0-47" pos="NOUN" morph="shekara:shekara=NOUN r:r=CONSTRUCT" start_char="280" end_char="287">shekarar</TOKEN>
<TOKEN id="token-0-48" pos="number" morph="none" start_char="289" end_char="292">2008</TOKEN>
<TOKEN id="token-0-49" pos="CONJ" morph="da:da=CONJ" start_char="294" end_char="295">da</TOKEN>
<TOKEN id="token-0-50" pos="NOUN" morph="shekara:shekara=NOUN r:r=CONSTRUCT" start_char="297" end_char="304">shekarar</TOKEN>
<TOKEN id="token-0-51" pos="NUM" morph="2009:2009=NUM" start_char="306" end_char="309">2009</TOKEN>
<TOKEN id="token-0-52" pos="punct" morph="none" start_char="310" end_char="310">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
