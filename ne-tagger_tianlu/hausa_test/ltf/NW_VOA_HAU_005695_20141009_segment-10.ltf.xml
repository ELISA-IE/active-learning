<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_VOA_HAU_005695_20141009_segment-10">
    <TEXT><SEG id="segment-10" start_char="948" end_char="1055">
<ORIGINAL_TEXT>Ga maganar cutar ebola ga na rashin cikakken tsaro dalili ke nan da suka sa ya samu hukumomi su yi wani abu.</ORIGINAL_TEXT>
<TOKEN id="token-10-0" pos="word" morph="none" start_char="948" end_char="949">Ga</TOKEN>
<TOKEN id="token-10-1" pos="word" morph="none" start_char="951" end_char="957">maganar</TOKEN>
<TOKEN id="token-10-2" pos="word" morph="none" start_char="959" end_char="963">cutar</TOKEN>
<TOKEN id="token-10-3" pos="word" morph="none" start_char="965" end_char="969">ebola</TOKEN>
<TOKEN id="token-10-4" pos="word" morph="none" start_char="971" end_char="972">ga</TOKEN>
<TOKEN id="token-10-5" pos="word" morph="none" start_char="974" end_char="975">na</TOKEN>
<TOKEN id="token-10-6" pos="word" morph="none" start_char="977" end_char="982">rashin</TOKEN>
<TOKEN id="token-10-7" pos="word" morph="none" start_char="984" end_char="991">cikakken</TOKEN>
<TOKEN id="token-10-8" pos="word" morph="none" start_char="993" end_char="997">tsaro</TOKEN>
<TOKEN id="token-10-9" pos="word" morph="none" start_char="999" end_char="1004">dalili</TOKEN>
<TOKEN id="token-10-10" pos="word" morph="none" start_char="1006" end_char="1007">ke</TOKEN>
<TOKEN id="token-10-11" pos="word" morph="none" start_char="1009" end_char="1011">nan</TOKEN>
<TOKEN id="token-10-12" pos="word" morph="none" start_char="1013" end_char="1014">da</TOKEN>
<TOKEN id="token-10-13" pos="word" morph="none" start_char="1016" end_char="1019">suka</TOKEN>
<TOKEN id="token-10-14" pos="word" morph="none" start_char="1021" end_char="1022">sa</TOKEN>
<TOKEN id="token-10-15" pos="word" morph="none" start_char="1024" end_char="1025">ya</TOKEN>
<TOKEN id="token-10-16" pos="word" morph="none" start_char="1027" end_char="1030">samu</TOKEN>
<TOKEN id="token-10-17" pos="word" morph="none" start_char="1032" end_char="1039">hukumomi</TOKEN>
<TOKEN id="token-10-18" pos="word" morph="none" start_char="1041" end_char="1042">su</TOKEN>
<TOKEN id="token-10-19" pos="word" morph="none" start_char="1044" end_char="1045">yi</TOKEN>
<TOKEN id="token-10-20" pos="word" morph="none" start_char="1047" end_char="1050">wani</TOKEN>
<TOKEN id="token-10-21" pos="word" morph="none" start_char="1052" end_char="1054">abu</TOKEN>
<TOKEN id="token-10-22" pos="punct" morph="none" start_char="1055" end_char="1055">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
