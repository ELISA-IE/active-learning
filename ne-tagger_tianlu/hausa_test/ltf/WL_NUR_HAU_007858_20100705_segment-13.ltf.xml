<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="WL_NUR_HAU_007858_20100705_segment-13">
    <TEXT><SEG id="segment-13" start_char="3049" end_char="3204">
<ORIGINAL_TEXT>Dangane da ayyukan wannan majalisa kuwa, to aikinta bai takaita kawai da Iran ba, tana gudanar da ayyuka da tarurruka na kara wa juna sani a sauran kasashe.</ORIGINAL_TEXT>
<TOKEN id="token-13-0" pos="word" morph="none" start_char="3049" end_char="3055">Dangane</TOKEN>
<TOKEN id="token-13-1" pos="word" morph="none" start_char="3057" end_char="3058">da</TOKEN>
<TOKEN id="token-13-2" pos="word" morph="none" start_char="3060" end_char="3066">ayyukan</TOKEN>
<TOKEN id="token-13-3" pos="word" morph="none" start_char="3068" end_char="3073">wannan</TOKEN>
<TOKEN id="token-13-4" pos="word" morph="none" start_char="3075" end_char="3082">majalisa</TOKEN>
<TOKEN id="token-13-5" pos="word" morph="none" start_char="3084" end_char="3087">kuwa</TOKEN>
<TOKEN id="token-13-6" pos="punct" morph="none" start_char="3088" end_char="3088">,</TOKEN>
<TOKEN id="token-13-7" pos="word" morph="none" start_char="3090" end_char="3091">to</TOKEN>
<TOKEN id="token-13-8" pos="word" morph="none" start_char="3093" end_char="3099">aikinta</TOKEN>
<TOKEN id="token-13-9" pos="word" morph="none" start_char="3101" end_char="3103">bai</TOKEN>
<TOKEN id="token-13-10" pos="word" morph="none" start_char="3105" end_char="3111">takaita</TOKEN>
<TOKEN id="token-13-11" pos="word" morph="none" start_char="3113" end_char="3117">kawai</TOKEN>
<TOKEN id="token-13-12" pos="word" morph="none" start_char="3119" end_char="3120">da</TOKEN>
<TOKEN id="token-13-13" pos="word" morph="none" start_char="3122" end_char="3125">Iran</TOKEN>
<TOKEN id="token-13-14" pos="word" morph="none" start_char="3127" end_char="3128">ba</TOKEN>
<TOKEN id="token-13-15" pos="punct" morph="none" start_char="3129" end_char="3129">,</TOKEN>
<TOKEN id="token-13-16" pos="word" morph="none" start_char="3131" end_char="3134">tana</TOKEN>
<TOKEN id="token-13-17" pos="word" morph="none" start_char="3136" end_char="3142">gudanar</TOKEN>
<TOKEN id="token-13-18" pos="word" morph="none" start_char="3144" end_char="3145">da</TOKEN>
<TOKEN id="token-13-19" pos="word" morph="none" start_char="3147" end_char="3152">ayyuka</TOKEN>
<TOKEN id="token-13-20" pos="word" morph="none" start_char="3154" end_char="3155">da</TOKEN>
<TOKEN id="token-13-21" pos="word" morph="none" start_char="3157" end_char="3165">tarurruka</TOKEN>
<TOKEN id="token-13-22" pos="word" morph="none" start_char="3167" end_char="3168">na</TOKEN>
<TOKEN id="token-13-23" pos="word" morph="none" start_char="3170" end_char="3173">kara</TOKEN>
<TOKEN id="token-13-24" pos="word" morph="none" start_char="3175" end_char="3176">wa</TOKEN>
<TOKEN id="token-13-25" pos="word" morph="none" start_char="3178" end_char="3181">juna</TOKEN>
<TOKEN id="token-13-26" pos="word" morph="none" start_char="3183" end_char="3186">sani</TOKEN>
<TOKEN id="token-13-27" pos="word" morph="none" start_char="3188" end_char="3188">a</TOKEN>
<TOKEN id="token-13-28" pos="word" morph="none" start_char="3190" end_char="3195">sauran</TOKEN>
<TOKEN id="token-13-29" pos="word" morph="none" start_char="3197" end_char="3203">kasashe</TOKEN>
<TOKEN id="token-13-30" pos="punct" morph="none" start_char="3204" end_char="3204">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
