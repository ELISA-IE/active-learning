<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="WL_DAN_HAU_007447_20110711_segment-12">
    <TEXT><SEG id="segment-12" start_char="1846" end_char="2048">
<ORIGINAL_TEXT>Misalin an bawa yan China dama suna shigo da hajarsu daga kasarsu suna talla, da kuwa mutanen Kano ke zuwa kasashen nasu suna siyowa, suna kuma tafiya musu abinda suke bukata daga nan suna siyarwa a can.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1846" end_char="1852">Misalin</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1854" end_char="1855">an</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1857" end_char="1860">bawa</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1862" end_char="1864">yan</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1866" end_char="1870">China</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1872" end_char="1875">dama</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1877" end_char="1880">suna</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1882" end_char="1886">shigo</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1888" end_char="1889">da</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1891" end_char="1897">hajarsu</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1899" end_char="1902">daga</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1904" end_char="1910">kasarsu</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1912" end_char="1915">suna</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1917" end_char="1921">talla</TOKEN>
<TOKEN id="token-12-14" pos="punct" morph="none" start_char="1922" end_char="1922">,</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1924" end_char="1925">da</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1927" end_char="1930">kuwa</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1932" end_char="1938">mutanen</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1940" end_char="1943">Kano</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1945" end_char="1946">ke</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1948" end_char="1951">zuwa</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1953" end_char="1960">kasashen</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1962" end_char="1965">nasu</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1967" end_char="1970">suna</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1972" end_char="1977">siyowa</TOKEN>
<TOKEN id="token-12-25" pos="punct" morph="none" start_char="1978" end_char="1978">,</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1980" end_char="1983">suna</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1985" end_char="1988">kuma</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="1990" end_char="1995">tafiya</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1997" end_char="2000">musu</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="2002" end_char="2007">abinda</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="2009" end_char="2012">suke</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="2014" end_char="2019">bukata</TOKEN>
<TOKEN id="token-12-33" pos="word" morph="none" start_char="2021" end_char="2024">daga</TOKEN>
<TOKEN id="token-12-34" pos="word" morph="none" start_char="2026" end_char="2028">nan</TOKEN>
<TOKEN id="token-12-35" pos="word" morph="none" start_char="2030" end_char="2033">suna</TOKEN>
<TOKEN id="token-12-36" pos="word" morph="none" start_char="2035" end_char="2041">siyarwa</TOKEN>
<TOKEN id="token-12-37" pos="word" morph="none" start_char="2043" end_char="2043">a</TOKEN>
<TOKEN id="token-12-38" pos="word" morph="none" start_char="2045" end_char="2047">can</TOKEN>
<TOKEN id="token-12-39" pos="punct" morph="none" start_char="2048" end_char="2048">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
