<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_VOA_HAU_002220_20120824_segment-2">
    <TEXT><SEG id="segment-2" start_char="219" end_char="637">
<ORIGINAL_TEXT>Wata sanarwar da ta fito daga maÊ¼aikatar lafiya ta kasar Angola da hukumar lafiya ta duniya da kuma asusun tallafawa kananan yara UNICEF suka bayar na nuni da cewa, an sami raguwar kananan yaran dake dauke da wannan cutar daga 33 a shekara ta dubu biyu da goma zuwa biyar a shekara ta dubu biyu da goma sha daya, yayinda ba a sami yaro ko guda daya dauke da kwayar cutar ba a shekarar nan ta dubu biyu da goma sha biyu.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="219" end_char="222">Wata</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="224" end_char="231">sanarwar</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="233" end_char="234">da</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="236" end_char="237">ta</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="239" end_char="242">fito</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="244" end_char="247">daga</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="249" end_char="258">maÊ¼aikatar</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="260" end_char="265">lafiya</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="267" end_char="268">ta</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="270" end_char="274">kasar</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="276" end_char="281">Angola</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="283" end_char="284">da</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="286" end_char="292">hukumar</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="294" end_char="299">lafiya</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="301" end_char="302">ta</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="304" end_char="309">duniya</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="311" end_char="312">da</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="314" end_char="317">kuma</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="319" end_char="324">asusun</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="326" end_char="334">tallafawa</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="336" end_char="342">kananan</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="344" end_char="347">yara</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="349" end_char="354">UNICEF</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="356" end_char="359">suka</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="361" end_char="365">bayar</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="367" end_char="368">na</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="370" end_char="373">nuni</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="375" end_char="376">da</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="378" end_char="381">cewa</TOKEN>
<TOKEN id="token-2-29" pos="punct" morph="none" start_char="382" end_char="382">,</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="384" end_char="385">an</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="387" end_char="390">sami</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="392" end_char="398">raguwar</TOKEN>
<TOKEN id="token-2-33" pos="word" morph="none" start_char="400" end_char="406">kananan</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="408" end_char="412">yaran</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="414" end_char="417">dake</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="419" end_char="423">dauke</TOKEN>
<TOKEN id="token-2-37" pos="word" morph="none" start_char="425" end_char="426">da</TOKEN>
<TOKEN id="token-2-38" pos="word" morph="none" start_char="428" end_char="433">wannan</TOKEN>
<TOKEN id="token-2-39" pos="word" morph="none" start_char="435" end_char="439">cutar</TOKEN>
<TOKEN id="token-2-40" pos="word" morph="none" start_char="441" end_char="444">daga</TOKEN>
<TOKEN id="token-2-41" pos="number" morph="none" start_char="446" end_char="447">33</TOKEN>
<TOKEN id="token-2-42" pos="word" morph="none" start_char="449" end_char="449">a</TOKEN>
<TOKEN id="token-2-43" pos="word" morph="none" start_char="451" end_char="457">shekara</TOKEN>
<TOKEN id="token-2-44" pos="word" morph="none" start_char="459" end_char="460">ta</TOKEN>
<TOKEN id="token-2-45" pos="word" morph="none" start_char="462" end_char="465">dubu</TOKEN>
<TOKEN id="token-2-46" pos="word" morph="none" start_char="467" end_char="470">biyu</TOKEN>
<TOKEN id="token-2-47" pos="word" morph="none" start_char="472" end_char="473">da</TOKEN>
<TOKEN id="token-2-48" pos="word" morph="none" start_char="475" end_char="478">goma</TOKEN>
<TOKEN id="token-2-49" pos="word" morph="none" start_char="480" end_char="483">zuwa</TOKEN>
<TOKEN id="token-2-50" pos="word" morph="none" start_char="485" end_char="489">biyar</TOKEN>
<TOKEN id="token-2-51" pos="word" morph="none" start_char="491" end_char="491">a</TOKEN>
<TOKEN id="token-2-52" pos="word" morph="none" start_char="493" end_char="499">shekara</TOKEN>
<TOKEN id="token-2-53" pos="word" morph="none" start_char="501" end_char="502">ta</TOKEN>
<TOKEN id="token-2-54" pos="word" morph="none" start_char="504" end_char="507">dubu</TOKEN>
<TOKEN id="token-2-55" pos="word" morph="none" start_char="509" end_char="512">biyu</TOKEN>
<TOKEN id="token-2-56" pos="word" morph="none" start_char="514" end_char="515">da</TOKEN>
<TOKEN id="token-2-57" pos="word" morph="none" start_char="517" end_char="520">goma</TOKEN>
<TOKEN id="token-2-58" pos="word" morph="none" start_char="522" end_char="524">sha</TOKEN>
<TOKEN id="token-2-59" pos="word" morph="none" start_char="526" end_char="529">daya</TOKEN>
<TOKEN id="token-2-60" pos="punct" morph="none" start_char="530" end_char="530">,</TOKEN>
<TOKEN id="token-2-61" pos="word" morph="none" start_char="532" end_char="538">yayinda</TOKEN>
<TOKEN id="token-2-62" pos="word" morph="none" start_char="540" end_char="541">ba</TOKEN>
<TOKEN id="token-2-63" pos="word" morph="none" start_char="543" end_char="543">a</TOKEN>
<TOKEN id="token-2-64" pos="word" morph="none" start_char="545" end_char="548">sami</TOKEN>
<TOKEN id="token-2-65" pos="word" morph="none" start_char="550" end_char="553">yaro</TOKEN>
<TOKEN id="token-2-66" pos="word" morph="none" start_char="555" end_char="556">ko</TOKEN>
<TOKEN id="token-2-67" pos="word" morph="none" start_char="558" end_char="561">guda</TOKEN>
<TOKEN id="token-2-68" pos="word" morph="none" start_char="563" end_char="566">daya</TOKEN>
<TOKEN id="token-2-69" pos="word" morph="none" start_char="568" end_char="572">dauke</TOKEN>
<TOKEN id="token-2-70" pos="word" morph="none" start_char="574" end_char="575">da</TOKEN>
<TOKEN id="token-2-71" pos="word" morph="none" start_char="577" end_char="582">kwayar</TOKEN>
<TOKEN id="token-2-72" pos="word" morph="none" start_char="584" end_char="588">cutar</TOKEN>
<TOKEN id="token-2-73" pos="word" morph="none" start_char="590" end_char="591">ba</TOKEN>
<TOKEN id="token-2-74" pos="word" morph="none" start_char="593" end_char="593">a</TOKEN>
<TOKEN id="token-2-75" pos="word" morph="none" start_char="595" end_char="602">shekarar</TOKEN>
<TOKEN id="token-2-76" pos="word" morph="none" start_char="604" end_char="606">nan</TOKEN>
<TOKEN id="token-2-77" pos="word" morph="none" start_char="608" end_char="609">ta</TOKEN>
<TOKEN id="token-2-78" pos="word" morph="none" start_char="611" end_char="614">dubu</TOKEN>
<TOKEN id="token-2-79" pos="word" morph="none" start_char="616" end_char="619">biyu</TOKEN>
<TOKEN id="token-2-80" pos="word" morph="none" start_char="621" end_char="622">da</TOKEN>
<TOKEN id="token-2-81" pos="word" morph="none" start_char="624" end_char="627">goma</TOKEN>
<TOKEN id="token-2-82" pos="word" morph="none" start_char="629" end_char="631">sha</TOKEN>
<TOKEN id="token-2-83" pos="word" morph="none" start_char="633" end_char="636">biyu</TOKEN>
<TOKEN id="token-2-84" pos="punct" morph="none" start_char="637" end_char="637">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
