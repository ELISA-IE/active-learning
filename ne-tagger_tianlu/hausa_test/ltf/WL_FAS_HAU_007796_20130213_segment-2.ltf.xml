<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="WL_FAS_HAU_007796_20130213_segment-2">
    <TEXT><SEG id="segment-2" start_char="115" end_char="229">
<ORIGINAL_TEXT>Shin, me yasa idan aka boye lamba daga wayar salula, kuma aka turo sakon tes da ita, sai lambar ta bayyana a sakon?</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="115" end_char="118">Shin</TOKEN>
<TOKEN id="token-2-1" pos="punct" morph="none" start_char="119" end_char="119">,</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="121" end_char="122">me</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="124" end_char="127">yasa</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="129" end_char="132">idan</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="134" end_char="136">aka</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="138" end_char="141">boye</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="143" end_char="147">lamba</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="149" end_char="152">daga</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="154" end_char="158">wayar</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="160" end_char="165">salula</TOKEN>
<TOKEN id="token-2-11" pos="punct" morph="none" start_char="166" end_char="166">,</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="168" end_char="171">kuma</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="173" end_char="175">aka</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="177" end_char="180">turo</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="182" end_char="186">sakon</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="188" end_char="190">tes</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="192" end_char="193">da</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="195" end_char="197">ita</TOKEN>
<TOKEN id="token-2-19" pos="punct" morph="none" start_char="198" end_char="198">,</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="200" end_char="202">sai</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="204" end_char="209">lambar</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="211" end_char="212">ta</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="214" end_char="220">bayyana</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="222" end_char="222">a</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="224" end_char="228">sakon</TOKEN>
<TOKEN id="token-2-26" pos="punct" morph="none" start_char="229" end_char="229">?</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
