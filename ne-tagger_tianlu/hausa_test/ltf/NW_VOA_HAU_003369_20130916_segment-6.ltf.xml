<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_VOA_HAU_003369_20130916_segment-6">
    <TEXT><SEG id="segment-6" start_char="1001" end_char="1159">
<ORIGINAL_TEXT>Sai dai suka ce, sakamakon binciken ya nuna yanayin mutanen da aka gudanar da binciken a kansu ne kawai ba za a iya sanin ko haka zata faru ga dukan jamaÊ¼a ba.</ORIGINAL_TEXT>
<TOKEN id="token-6-0" pos="word" morph="none" start_char="1001" end_char="1003">Sai</TOKEN>
<TOKEN id="token-6-1" pos="word" morph="none" start_char="1005" end_char="1007">dai</TOKEN>
<TOKEN id="token-6-2" pos="word" morph="none" start_char="1009" end_char="1012">suka</TOKEN>
<TOKEN id="token-6-3" pos="word" morph="none" start_char="1014" end_char="1015">ce</TOKEN>
<TOKEN id="token-6-4" pos="punct" morph="none" start_char="1016" end_char="1016">,</TOKEN>
<TOKEN id="token-6-5" pos="word" morph="none" start_char="1018" end_char="1026">sakamakon</TOKEN>
<TOKEN id="token-6-6" pos="word" morph="none" start_char="1028" end_char="1035">binciken</TOKEN>
<TOKEN id="token-6-7" pos="word" morph="none" start_char="1037" end_char="1038">ya</TOKEN>
<TOKEN id="token-6-8" pos="word" morph="none" start_char="1040" end_char="1043">nuna</TOKEN>
<TOKEN id="token-6-9" pos="word" morph="none" start_char="1045" end_char="1051">yanayin</TOKEN>
<TOKEN id="token-6-10" pos="word" morph="none" start_char="1053" end_char="1059">mutanen</TOKEN>
<TOKEN id="token-6-11" pos="word" morph="none" start_char="1061" end_char="1062">da</TOKEN>
<TOKEN id="token-6-12" pos="word" morph="none" start_char="1064" end_char="1066">aka</TOKEN>
<TOKEN id="token-6-13" pos="word" morph="none" start_char="1068" end_char="1074">gudanar</TOKEN>
<TOKEN id="token-6-14" pos="word" morph="none" start_char="1076" end_char="1077">da</TOKEN>
<TOKEN id="token-6-15" pos="word" morph="none" start_char="1079" end_char="1086">binciken</TOKEN>
<TOKEN id="token-6-16" pos="word" morph="none" start_char="1088" end_char="1088">a</TOKEN>
<TOKEN id="token-6-17" pos="word" morph="none" start_char="1090" end_char="1094">kansu</TOKEN>
<TOKEN id="token-6-18" pos="word" morph="none" start_char="1096" end_char="1097">ne</TOKEN>
<TOKEN id="token-6-19" pos="word" morph="none" start_char="1099" end_char="1103">kawai</TOKEN>
<TOKEN id="token-6-20" pos="word" morph="none" start_char="1105" end_char="1106">ba</TOKEN>
<TOKEN id="token-6-21" pos="word" morph="none" start_char="1108" end_char="1109">za</TOKEN>
<TOKEN id="token-6-22" pos="word" morph="none" start_char="1111" end_char="1111">a</TOKEN>
<TOKEN id="token-6-23" pos="word" morph="none" start_char="1113" end_char="1115">iya</TOKEN>
<TOKEN id="token-6-24" pos="word" morph="none" start_char="1117" end_char="1121">sanin</TOKEN>
<TOKEN id="token-6-25" pos="word" morph="none" start_char="1123" end_char="1124">ko</TOKEN>
<TOKEN id="token-6-26" pos="word" morph="none" start_char="1126" end_char="1129">haka</TOKEN>
<TOKEN id="token-6-27" pos="word" morph="none" start_char="1131" end_char="1134">zata</TOKEN>
<TOKEN id="token-6-28" pos="word" morph="none" start_char="1136" end_char="1139">faru</TOKEN>
<TOKEN id="token-6-29" pos="word" morph="none" start_char="1141" end_char="1142">ga</TOKEN>
<TOKEN id="token-6-30" pos="word" morph="none" start_char="1144" end_char="1148">dukan</TOKEN>
<TOKEN id="token-6-31" pos="word" morph="none" start_char="1150" end_char="1155">jamaÊ¼a</TOKEN>
<TOKEN id="token-6-32" pos="word" morph="none" start_char="1157" end_char="1158">ba</TOKEN>
<TOKEN id="token-6-33" pos="punct" morph="none" start_char="1159" end_char="1159">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
