<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_VOA_HAU_004678_20140423_segment-12">
    <TEXT><SEG id="segment-12" start_char="1340" end_char="1500">
<ORIGINAL_TEXT>Yace sai ka ga mutum ya sha mangwaro ko lemu sai ya jefar da kwallon ko bawon akan hanya duk da tanadin wuraren da zaʼa sa shara a koina har ma da gefen hanyoyi.</ORIGINAL_TEXT>
<TOKEN id="token-12-0" pos="word" morph="none" start_char="1340" end_char="1343">Yace</TOKEN>
<TOKEN id="token-12-1" pos="word" morph="none" start_char="1345" end_char="1347">sai</TOKEN>
<TOKEN id="token-12-2" pos="word" morph="none" start_char="1349" end_char="1350">ka</TOKEN>
<TOKEN id="token-12-3" pos="word" morph="none" start_char="1352" end_char="1353">ga</TOKEN>
<TOKEN id="token-12-4" pos="word" morph="none" start_char="1355" end_char="1359">mutum</TOKEN>
<TOKEN id="token-12-5" pos="word" morph="none" start_char="1361" end_char="1362">ya</TOKEN>
<TOKEN id="token-12-6" pos="word" morph="none" start_char="1364" end_char="1366">sha</TOKEN>
<TOKEN id="token-12-7" pos="word" morph="none" start_char="1368" end_char="1375">mangwaro</TOKEN>
<TOKEN id="token-12-8" pos="word" morph="none" start_char="1377" end_char="1378">ko</TOKEN>
<TOKEN id="token-12-9" pos="word" morph="none" start_char="1380" end_char="1383">lemu</TOKEN>
<TOKEN id="token-12-10" pos="word" morph="none" start_char="1385" end_char="1387">sai</TOKEN>
<TOKEN id="token-12-11" pos="word" morph="none" start_char="1389" end_char="1390">ya</TOKEN>
<TOKEN id="token-12-12" pos="word" morph="none" start_char="1392" end_char="1396">jefar</TOKEN>
<TOKEN id="token-12-13" pos="word" morph="none" start_char="1398" end_char="1399">da</TOKEN>
<TOKEN id="token-12-14" pos="word" morph="none" start_char="1401" end_char="1407">kwallon</TOKEN>
<TOKEN id="token-12-15" pos="word" morph="none" start_char="1409" end_char="1410">ko</TOKEN>
<TOKEN id="token-12-16" pos="word" morph="none" start_char="1412" end_char="1416">bawon</TOKEN>
<TOKEN id="token-12-17" pos="word" morph="none" start_char="1418" end_char="1421">akan</TOKEN>
<TOKEN id="token-12-18" pos="word" morph="none" start_char="1423" end_char="1427">hanya</TOKEN>
<TOKEN id="token-12-19" pos="word" morph="none" start_char="1429" end_char="1431">duk</TOKEN>
<TOKEN id="token-12-20" pos="word" morph="none" start_char="1433" end_char="1434">da</TOKEN>
<TOKEN id="token-12-21" pos="word" morph="none" start_char="1436" end_char="1442">tanadin</TOKEN>
<TOKEN id="token-12-22" pos="word" morph="none" start_char="1444" end_char="1450">wuraren</TOKEN>
<TOKEN id="token-12-23" pos="word" morph="none" start_char="1452" end_char="1453">da</TOKEN>
<TOKEN id="token-12-24" pos="word" morph="none" start_char="1455" end_char="1458">zaʼa</TOKEN>
<TOKEN id="token-12-25" pos="word" morph="none" start_char="1460" end_char="1461">sa</TOKEN>
<TOKEN id="token-12-26" pos="word" morph="none" start_char="1463" end_char="1467">shara</TOKEN>
<TOKEN id="token-12-27" pos="word" morph="none" start_char="1469" end_char="1469">a</TOKEN>
<TOKEN id="token-12-28" pos="word" morph="none" start_char="1471" end_char="1475">koina</TOKEN>
<TOKEN id="token-12-29" pos="word" morph="none" start_char="1477" end_char="1479">har</TOKEN>
<TOKEN id="token-12-30" pos="word" morph="none" start_char="1481" end_char="1482">ma</TOKEN>
<TOKEN id="token-12-31" pos="word" morph="none" start_char="1484" end_char="1485">da</TOKEN>
<TOKEN id="token-12-32" pos="word" morph="none" start_char="1487" end_char="1491">gefen</TOKEN>
<TOKEN id="token-12-33" pos="word" morph="none" start_char="1493" end_char="1499">hanyoyi</TOKEN>
<TOKEN id="token-12-34" pos="punct" morph="none" start_char="1500" end_char="1500">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
