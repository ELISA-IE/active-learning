<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="WL_NUR_HAU_007862_20100705_segment-9">
    <TEXT><SEG id="segment-9" start_char="1276" end_char="1490">
<ORIGINAL_TEXT>Da yake kuma Allah Ya ba shi wata irin kwanya ta saurin fahimta, yana da shekara goma, kusan duk ya karance litattafan dalibai na sama da shi a tarihi da mukaddamar ilimin shariÊ¼a da kuma sauran fannoni daban-daban.</ORIGINAL_TEXT>
<TOKEN id="token-9-0" pos="word" morph="none" start_char="1276" end_char="1277">Da</TOKEN>
<TOKEN id="token-9-1" pos="word" morph="none" start_char="1279" end_char="1282">yake</TOKEN>
<TOKEN id="token-9-2" pos="word" morph="none" start_char="1284" end_char="1287">kuma</TOKEN>
<TOKEN id="token-9-3" pos="word" morph="none" start_char="1289" end_char="1293">Allah</TOKEN>
<TOKEN id="token-9-4" pos="word" morph="none" start_char="1295" end_char="1296">Ya</TOKEN>
<TOKEN id="token-9-5" pos="word" morph="none" start_char="1298" end_char="1299">ba</TOKEN>
<TOKEN id="token-9-6" pos="word" morph="none" start_char="1301" end_char="1303">shi</TOKEN>
<TOKEN id="token-9-7" pos="word" morph="none" start_char="1305" end_char="1308">wata</TOKEN>
<TOKEN id="token-9-8" pos="word" morph="none" start_char="1310" end_char="1313">irin</TOKEN>
<TOKEN id="token-9-9" pos="word" morph="none" start_char="1315" end_char="1320">kwanya</TOKEN>
<TOKEN id="token-9-10" pos="word" morph="none" start_char="1322" end_char="1323">ta</TOKEN>
<TOKEN id="token-9-11" pos="word" morph="none" start_char="1325" end_char="1330">saurin</TOKEN>
<TOKEN id="token-9-12" pos="word" morph="none" start_char="1332" end_char="1338">fahimta</TOKEN>
<TOKEN id="token-9-13" pos="punct" morph="none" start_char="1339" end_char="1339">,</TOKEN>
<TOKEN id="token-9-14" pos="word" morph="none" start_char="1341" end_char="1344">yana</TOKEN>
<TOKEN id="token-9-15" pos="word" morph="none" start_char="1346" end_char="1347">da</TOKEN>
<TOKEN id="token-9-16" pos="word" morph="none" start_char="1349" end_char="1355">shekara</TOKEN>
<TOKEN id="token-9-17" pos="word" morph="none" start_char="1357" end_char="1360">goma</TOKEN>
<TOKEN id="token-9-18" pos="punct" morph="none" start_char="1361" end_char="1361">,</TOKEN>
<TOKEN id="token-9-19" pos="word" morph="none" start_char="1363" end_char="1367">kusan</TOKEN>
<TOKEN id="token-9-20" pos="word" morph="none" start_char="1369" end_char="1371">duk</TOKEN>
<TOKEN id="token-9-21" pos="word" morph="none" start_char="1373" end_char="1374">ya</TOKEN>
<TOKEN id="token-9-22" pos="word" morph="none" start_char="1376" end_char="1382">karance</TOKEN>
<TOKEN id="token-9-23" pos="word" morph="none" start_char="1384" end_char="1393">litattafan</TOKEN>
<TOKEN id="token-9-24" pos="word" morph="none" start_char="1395" end_char="1401">dalibai</TOKEN>
<TOKEN id="token-9-25" pos="word" morph="none" start_char="1403" end_char="1404">na</TOKEN>
<TOKEN id="token-9-26" pos="word" morph="none" start_char="1406" end_char="1409">sama</TOKEN>
<TOKEN id="token-9-27" pos="word" morph="none" start_char="1411" end_char="1412">da</TOKEN>
<TOKEN id="token-9-28" pos="word" morph="none" start_char="1414" end_char="1416">shi</TOKEN>
<TOKEN id="token-9-29" pos="word" morph="none" start_char="1418" end_char="1418">a</TOKEN>
<TOKEN id="token-9-30" pos="word" morph="none" start_char="1420" end_char="1425">tarihi</TOKEN>
<TOKEN id="token-9-31" pos="word" morph="none" start_char="1427" end_char="1428">da</TOKEN>
<TOKEN id="token-9-32" pos="word" morph="none" start_char="1430" end_char="1439">mukaddamar</TOKEN>
<TOKEN id="token-9-33" pos="word" morph="none" start_char="1441" end_char="1446">ilimin</TOKEN>
<TOKEN id="token-9-34" pos="word" morph="none" start_char="1448" end_char="1454">shariÊ¼a</TOKEN>
<TOKEN id="token-9-35" pos="word" morph="none" start_char="1456" end_char="1457">da</TOKEN>
<TOKEN id="token-9-36" pos="word" morph="none" start_char="1459" end_char="1462">kuma</TOKEN>
<TOKEN id="token-9-37" pos="word" morph="none" start_char="1464" end_char="1469">sauran</TOKEN>
<TOKEN id="token-9-38" pos="word" morph="none" start_char="1471" end_char="1477">fannoni</TOKEN>
<TOKEN id="token-9-39" pos="word" morph="none" start_char="1479" end_char="1483">daban</TOKEN>
<TOKEN id="token-9-40" pos="punct" morph="none" start_char="1484" end_char="1484">-</TOKEN>
<TOKEN id="token-9-41" pos="word" morph="none" start_char="1485" end_char="1489">daban</TOKEN>
<TOKEN id="token-9-42" pos="punct" morph="none" start_char="1490" end_char="1490">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
