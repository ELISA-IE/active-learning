<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_VOA_HAU_002116_20120711_segment-2">
    <TEXT><SEG id="segment-2" start_char="452" end_char="619">
<ORIGINAL_TEXT>Idan sakamakon ya nuna cewa, mutum yana dauke da kwayar cutar kanjamau, ana bukatarshi ya tafi wajen likita domin sake yin gwajin da zai tabbatar da sakamakon na farko.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="452" end_char="455">Idan</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="457" end_char="465">sakamakon</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="467" end_char="468">ya</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="470" end_char="473">nuna</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="475" end_char="478">cewa</TOKEN>
<TOKEN id="token-2-5" pos="punct" morph="none" start_char="479" end_char="479">,</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="481" end_char="485">mutum</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="487" end_char="490">yana</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="492" end_char="496">dauke</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="498" end_char="499">da</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="501" end_char="506">kwayar</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="508" end_char="512">cutar</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="514" end_char="521">kanjamau</TOKEN>
<TOKEN id="token-2-13" pos="punct" morph="none" start_char="522" end_char="522">,</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="524" end_char="526">ana</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="528" end_char="537">bukatarshi</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="539" end_char="540">ya</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="542" end_char="545">tafi</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="547" end_char="551">wajen</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="553" end_char="558">likita</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="560" end_char="564">domin</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="566" end_char="569">sake</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="571" end_char="573">yin</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="575" end_char="580">gwajin</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="582" end_char="583">da</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="585" end_char="587">zai</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="589" end_char="596">tabbatar</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="598" end_char="599">da</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="601" end_char="609">sakamakon</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="611" end_char="612">na</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="614" end_char="618">farko</TOKEN>
<TOKEN id="token-2-31" pos="punct" morph="none" start_char="619" end_char="619">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
