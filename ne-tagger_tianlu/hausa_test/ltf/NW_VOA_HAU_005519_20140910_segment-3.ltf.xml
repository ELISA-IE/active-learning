<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_VOA_HAU_005519_20140910_segment-3">
    <TEXT><SEG id="segment-3" start_char="331" end_char="645">
<ORIGINAL_TEXT>Kusan rabin wannan adadi na mutanen da cutar ta hallaka ko suka kamu da ita duk a Laberiya suke.Rahoton da hukumar ta bayar jiya gameda Laberiya a ciki tayi gargadin cewa cutar “zata rubanya ninkin- ba- ninkin”, kuma tayi harsashen cewa za a ga Karin dubban mutane da zasu kamu da cutar cikin makonni uku masu zuwa.</ORIGINAL_TEXT>
<TOKEN id="token-3-0" pos="word" morph="none" start_char="331" end_char="335">Kusan</TOKEN>
<TOKEN id="token-3-1" pos="word" morph="none" start_char="337" end_char="341">rabin</TOKEN>
<TOKEN id="token-3-2" pos="word" morph="none" start_char="343" end_char="348">wannan</TOKEN>
<TOKEN id="token-3-3" pos="word" morph="none" start_char="350" end_char="354">adadi</TOKEN>
<TOKEN id="token-3-4" pos="word" morph="none" start_char="356" end_char="357">na</TOKEN>
<TOKEN id="token-3-5" pos="word" morph="none" start_char="359" end_char="365">mutanen</TOKEN>
<TOKEN id="token-3-6" pos="word" morph="none" start_char="367" end_char="368">da</TOKEN>
<TOKEN id="token-3-7" pos="word" morph="none" start_char="370" end_char="374">cutar</TOKEN>
<TOKEN id="token-3-8" pos="word" morph="none" start_char="376" end_char="377">ta</TOKEN>
<TOKEN id="token-3-9" pos="word" morph="none" start_char="379" end_char="385">hallaka</TOKEN>
<TOKEN id="token-3-10" pos="word" morph="none" start_char="387" end_char="388">ko</TOKEN>
<TOKEN id="token-3-11" pos="word" morph="none" start_char="390" end_char="393">suka</TOKEN>
<TOKEN id="token-3-12" pos="word" morph="none" start_char="395" end_char="398">kamu</TOKEN>
<TOKEN id="token-3-13" pos="word" morph="none" start_char="400" end_char="401">da</TOKEN>
<TOKEN id="token-3-14" pos="word" morph="none" start_char="403" end_char="405">ita</TOKEN>
<TOKEN id="token-3-15" pos="word" morph="none" start_char="407" end_char="409">duk</TOKEN>
<TOKEN id="token-3-16" pos="word" morph="none" start_char="411" end_char="411">a</TOKEN>
<TOKEN id="token-3-17" pos="word" morph="none" start_char="413" end_char="420">Laberiya</TOKEN>
<TOKEN id="token-3-18" pos="word" morph="none" start_char="422" end_char="425">suke</TOKEN>
<TOKEN id="token-3-19" pos="punct" morph="none" start_char="426" end_char="426">.</TOKEN>
<TOKEN id="token-3-20" pos="word" morph="none" start_char="427" end_char="433">Rahoton</TOKEN>
<TOKEN id="token-3-21" pos="word" morph="none" start_char="435" end_char="436">da</TOKEN>
<TOKEN id="token-3-22" pos="word" morph="none" start_char="438" end_char="444">hukumar</TOKEN>
<TOKEN id="token-3-23" pos="word" morph="none" start_char="446" end_char="447">ta</TOKEN>
<TOKEN id="token-3-24" pos="word" morph="none" start_char="449" end_char="453">bayar</TOKEN>
<TOKEN id="token-3-25" pos="word" morph="none" start_char="455" end_char="458">jiya</TOKEN>
<TOKEN id="token-3-26" pos="word" morph="none" start_char="460" end_char="465">gameda</TOKEN>
<TOKEN id="token-3-27" pos="word" morph="none" start_char="467" end_char="474">Laberiya</TOKEN>
<TOKEN id="token-3-28" pos="word" morph="none" start_char="476" end_char="476">a</TOKEN>
<TOKEN id="token-3-29" pos="word" morph="none" start_char="478" end_char="481">ciki</TOKEN>
<TOKEN id="token-3-30" pos="word" morph="none" start_char="483" end_char="486">tayi</TOKEN>
<TOKEN id="token-3-31" pos="word" morph="none" start_char="488" end_char="495">gargadin</TOKEN>
<TOKEN id="token-3-32" pos="word" morph="none" start_char="497" end_char="500">cewa</TOKEN>
<TOKEN id="token-3-33" pos="word" morph="none" start_char="502" end_char="506">cutar</TOKEN>
<TOKEN id="token-3-34" pos="punct" morph="none" start_char="508" end_char="508">“</TOKEN>
<TOKEN id="token-3-35" pos="word" morph="none" start_char="509" end_char="512">zata</TOKEN>
<TOKEN id="token-3-36" pos="word" morph="none" start_char="514" end_char="520">rubanya</TOKEN>
<TOKEN id="token-3-37" pos="word" morph="none" start_char="522" end_char="527">ninkin</TOKEN>
<TOKEN id="token-3-38" pos="punct" morph="none" start_char="528" end_char="528">-</TOKEN>
<TOKEN id="token-3-39" pos="word" morph="none" start_char="530" end_char="531">ba</TOKEN>
<TOKEN id="token-3-40" pos="punct" morph="none" start_char="532" end_char="532">-</TOKEN>
<TOKEN id="token-3-41" pos="word" morph="none" start_char="534" end_char="539">ninkin</TOKEN>
<TOKEN id="token-3-42" pos="punct" morph="none" start_char="540" end_char="541">”,</TOKEN>
<TOKEN id="token-3-43" pos="word" morph="none" start_char="543" end_char="546">kuma</TOKEN>
<TOKEN id="token-3-44" pos="word" morph="none" start_char="548" end_char="551">tayi</TOKEN>
<TOKEN id="token-3-45" pos="word" morph="none" start_char="553" end_char="561">harsashen</TOKEN>
<TOKEN id="token-3-46" pos="word" morph="none" start_char="563" end_char="566">cewa</TOKEN>
<TOKEN id="token-3-47" pos="word" morph="none" start_char="568" end_char="569">za</TOKEN>
<TOKEN id="token-3-48" pos="word" morph="none" start_char="571" end_char="571">a</TOKEN>
<TOKEN id="token-3-49" pos="word" morph="none" start_char="573" end_char="574">ga</TOKEN>
<TOKEN id="token-3-50" pos="word" morph="none" start_char="576" end_char="580">Karin</TOKEN>
<TOKEN id="token-3-51" pos="word" morph="none" start_char="582" end_char="587">dubban</TOKEN>
<TOKEN id="token-3-52" pos="word" morph="none" start_char="589" end_char="594">mutane</TOKEN>
<TOKEN id="token-3-53" pos="word" morph="none" start_char="596" end_char="597">da</TOKEN>
<TOKEN id="token-3-54" pos="word" morph="none" start_char="599" end_char="602">zasu</TOKEN>
<TOKEN id="token-3-55" pos="word" morph="none" start_char="604" end_char="607">kamu</TOKEN>
<TOKEN id="token-3-56" pos="word" morph="none" start_char="609" end_char="610">da</TOKEN>
<TOKEN id="token-3-57" pos="word" morph="none" start_char="612" end_char="616">cutar</TOKEN>
<TOKEN id="token-3-58" pos="word" morph="none" start_char="618" end_char="622">cikin</TOKEN>
<TOKEN id="token-3-59" pos="word" morph="none" start_char="624" end_char="630">makonni</TOKEN>
<TOKEN id="token-3-60" pos="word" morph="none" start_char="632" end_char="634">uku</TOKEN>
<TOKEN id="token-3-61" pos="word" morph="none" start_char="636" end_char="639">masu</TOKEN>
<TOKEN id="token-3-62" pos="word" morph="none" start_char="641" end_char="644">zuwa</TOKEN>
<TOKEN id="token-3-63" pos="punct" morph="none" start_char="645" end_char="645">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
