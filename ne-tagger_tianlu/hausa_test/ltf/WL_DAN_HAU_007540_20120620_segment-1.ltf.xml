<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="WL_DAN_HAU_007540_20120620_segment-1">
    <TEXT><SEG id="segment-1" start_char="60" end_char="244">
<ORIGINAL_TEXT>Aminci a gare ku ya ku Ê¼yan uwana Musulmai maza da mata, yara da manya, kasarmu Nijeriya na cikin wani mummunan hali, halin da idan ya ci gaba da faruwa to nan gaba komai na iya faruwa.</ORIGINAL_TEXT>
<TOKEN id="token-1-0" pos="word" morph="none" start_char="60" end_char="65">Aminci</TOKEN>
<TOKEN id="token-1-1" pos="word" morph="none" start_char="67" end_char="67">a</TOKEN>
<TOKEN id="token-1-2" pos="word" morph="none" start_char="69" end_char="72">gare</TOKEN>
<TOKEN id="token-1-3" pos="word" morph="none" start_char="74" end_char="75">ku</TOKEN>
<TOKEN id="token-1-4" pos="word" morph="none" start_char="77" end_char="78">ya</TOKEN>
<TOKEN id="token-1-5" pos="word" morph="none" start_char="80" end_char="81">ku</TOKEN>
<TOKEN id="token-1-6" pos="word" morph="none" start_char="83" end_char="86">Ê¼yan</TOKEN>
<TOKEN id="token-1-7" pos="word" morph="none" start_char="88" end_char="92">uwana</TOKEN>
<TOKEN id="token-1-8" pos="word" morph="none" start_char="94" end_char="101">Musulmai</TOKEN>
<TOKEN id="token-1-9" pos="word" morph="none" start_char="103" end_char="106">maza</TOKEN>
<TOKEN id="token-1-10" pos="word" morph="none" start_char="108" end_char="109">da</TOKEN>
<TOKEN id="token-1-11" pos="word" morph="none" start_char="111" end_char="114">mata</TOKEN>
<TOKEN id="token-1-12" pos="punct" morph="none" start_char="115" end_char="115">,</TOKEN>
<TOKEN id="token-1-13" pos="word" morph="none" start_char="117" end_char="120">yara</TOKEN>
<TOKEN id="token-1-14" pos="word" morph="none" start_char="122" end_char="123">da</TOKEN>
<TOKEN id="token-1-15" pos="word" morph="none" start_char="125" end_char="129">manya</TOKEN>
<TOKEN id="token-1-16" pos="punct" morph="none" start_char="130" end_char="130">,</TOKEN>
<TOKEN id="token-1-17" pos="word" morph="none" start_char="132" end_char="138">kasarmu</TOKEN>
<TOKEN id="token-1-18" pos="word" morph="none" start_char="140" end_char="147">Nijeriya</TOKEN>
<TOKEN id="token-1-19" pos="word" morph="none" start_char="149" end_char="150">na</TOKEN>
<TOKEN id="token-1-20" pos="word" morph="none" start_char="152" end_char="156">cikin</TOKEN>
<TOKEN id="token-1-21" pos="word" morph="none" start_char="158" end_char="161">wani</TOKEN>
<TOKEN id="token-1-22" pos="word" morph="none" start_char="163" end_char="170">mummunan</TOKEN>
<TOKEN id="token-1-23" pos="word" morph="none" start_char="172" end_char="175">hali</TOKEN>
<TOKEN id="token-1-24" pos="punct" morph="none" start_char="176" end_char="176">,</TOKEN>
<TOKEN id="token-1-25" pos="word" morph="none" start_char="178" end_char="182">halin</TOKEN>
<TOKEN id="token-1-26" pos="word" morph="none" start_char="184" end_char="185">da</TOKEN>
<TOKEN id="token-1-27" pos="word" morph="none" start_char="187" end_char="190">idan</TOKEN>
<TOKEN id="token-1-28" pos="word" morph="none" start_char="192" end_char="193">ya</TOKEN>
<TOKEN id="token-1-29" pos="word" morph="none" start_char="195" end_char="196">ci</TOKEN>
<TOKEN id="token-1-30" pos="word" morph="none" start_char="198" end_char="201">gaba</TOKEN>
<TOKEN id="token-1-31" pos="word" morph="none" start_char="203" end_char="204">da</TOKEN>
<TOKEN id="token-1-32" pos="word" morph="none" start_char="206" end_char="211">faruwa</TOKEN>
<TOKEN id="token-1-33" pos="word" morph="none" start_char="213" end_char="214">to</TOKEN>
<TOKEN id="token-1-34" pos="word" morph="none" start_char="216" end_char="218">nan</TOKEN>
<TOKEN id="token-1-35" pos="word" morph="none" start_char="220" end_char="223">gaba</TOKEN>
<TOKEN id="token-1-36" pos="word" morph="none" start_char="225" end_char="229">komai</TOKEN>
<TOKEN id="token-1-37" pos="word" morph="none" start_char="231" end_char="232">na</TOKEN>
<TOKEN id="token-1-38" pos="word" morph="none" start_char="234" end_char="236">iya</TOKEN>
<TOKEN id="token-1-39" pos="word" morph="none" start_char="238" end_char="243">faruwa</TOKEN>
<TOKEN id="token-1-40" pos="punct" morph="none" start_char="244" end_char="244">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
