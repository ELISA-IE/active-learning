<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="WL_DAN_HAU_007576_20130531_segment-2">
    <TEXT><SEG id="segment-2" start_char="259" end_char="487">
<ORIGINAL_TEXT>Nan aka ci gaba da hira da sirikarsa da matarsa da sauran mutanen gida, sai katsam aka dauke wuta, nan fa Bazazzage yaga duhu sai yasa hannu ya dauki cinya yana ci yana baza ido, ba za to ba tsammani kwatsam sai aka dawo da wuta.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="259" end_char="261">Nan</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="263" end_char="265">aka</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="267" end_char="268">ci</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="270" end_char="273">gaba</TOKEN>
<TOKEN id="token-2-4" pos="word" morph="none" start_char="275" end_char="276">da</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="278" end_char="281">hira</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="283" end_char="284">da</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="286" end_char="294">sirikarsa</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="296" end_char="297">da</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="299" end_char="305">matarsa</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="307" end_char="308">da</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="310" end_char="315">sauran</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="317" end_char="323">mutanen</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="325" end_char="328">gida</TOKEN>
<TOKEN id="token-2-14" pos="punct" morph="none" start_char="329" end_char="329">,</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="331" end_char="333">sai</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="335" end_char="340">katsam</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="342" end_char="344">aka</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="346" end_char="350">dauke</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="352" end_char="355">wuta</TOKEN>
<TOKEN id="token-2-20" pos="punct" morph="none" start_char="356" end_char="356">,</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="358" end_char="360">nan</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="362" end_char="363">fa</TOKEN>
<TOKEN id="token-2-23" pos="word" morph="none" start_char="365" end_char="373">Bazazzage</TOKEN>
<TOKEN id="token-2-24" pos="word" morph="none" start_char="375" end_char="378">yaga</TOKEN>
<TOKEN id="token-2-25" pos="word" morph="none" start_char="380" end_char="383">duhu</TOKEN>
<TOKEN id="token-2-26" pos="word" morph="none" start_char="385" end_char="387">sai</TOKEN>
<TOKEN id="token-2-27" pos="word" morph="none" start_char="389" end_char="392">yasa</TOKEN>
<TOKEN id="token-2-28" pos="word" morph="none" start_char="394" end_char="398">hannu</TOKEN>
<TOKEN id="token-2-29" pos="word" morph="none" start_char="400" end_char="401">ya</TOKEN>
<TOKEN id="token-2-30" pos="word" morph="none" start_char="403" end_char="407">dauki</TOKEN>
<TOKEN id="token-2-31" pos="word" morph="none" start_char="409" end_char="413">cinya</TOKEN>
<TOKEN id="token-2-32" pos="word" morph="none" start_char="415" end_char="418">yana</TOKEN>
<TOKEN id="token-2-33" pos="word" morph="none" start_char="420" end_char="421">ci</TOKEN>
<TOKEN id="token-2-34" pos="word" morph="none" start_char="423" end_char="426">yana</TOKEN>
<TOKEN id="token-2-35" pos="word" morph="none" start_char="428" end_char="431">baza</TOKEN>
<TOKEN id="token-2-36" pos="word" morph="none" start_char="433" end_char="435">ido</TOKEN>
<TOKEN id="token-2-37" pos="punct" morph="none" start_char="436" end_char="436">,</TOKEN>
<TOKEN id="token-2-38" pos="word" morph="none" start_char="438" end_char="439">ba</TOKEN>
<TOKEN id="token-2-39" pos="word" morph="none" start_char="441" end_char="442">za</TOKEN>
<TOKEN id="token-2-40" pos="word" morph="none" start_char="444" end_char="445">to</TOKEN>
<TOKEN id="token-2-41" pos="word" morph="none" start_char="447" end_char="448">ba</TOKEN>
<TOKEN id="token-2-42" pos="word" morph="none" start_char="450" end_char="457">tsammani</TOKEN>
<TOKEN id="token-2-43" pos="word" morph="none" start_char="459" end_char="465">kwatsam</TOKEN>
<TOKEN id="token-2-44" pos="word" morph="none" start_char="467" end_char="469">sai</TOKEN>
<TOKEN id="token-2-45" pos="word" morph="none" start_char="471" end_char="473">aka</TOKEN>
<TOKEN id="token-2-46" pos="word" morph="none" start_char="475" end_char="478">dawo</TOKEN>
<TOKEN id="token-2-47" pos="word" morph="none" start_char="480" end_char="481">da</TOKEN>
<TOKEN id="token-2-48" pos="word" morph="none" start_char="483" end_char="486">wuta</TOKEN>
<TOKEN id="token-2-49" pos="punct" morph="none" start_char="487" end_char="487">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
