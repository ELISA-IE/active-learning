<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_VOA_HAU_005655_20141002_segment-11">
    <TEXT><SEG id="segment-11" start_char="716" end_char="885">
<ORIGINAL_TEXT>Hajiya Hafsat Muhammed Baba ta gabatar da kasida mai taken "Arewa ina muka dosa" Tace yakamata Ê¼yan arewa su hada kansu su kuma san inda suka fito da kuma inda suka nufa.</ORIGINAL_TEXT>
<TOKEN id="token-11-0" pos="word" morph="none" start_char="716" end_char="721">Hajiya</TOKEN>
<TOKEN id="token-11-1" pos="word" morph="none" start_char="723" end_char="728">Hafsat</TOKEN>
<TOKEN id="token-11-2" pos="word" morph="none" start_char="730" end_char="737">Muhammed</TOKEN>
<TOKEN id="token-11-3" pos="word" morph="none" start_char="739" end_char="742">Baba</TOKEN>
<TOKEN id="token-11-4" pos="word" morph="none" start_char="744" end_char="745">ta</TOKEN>
<TOKEN id="token-11-5" pos="word" morph="none" start_char="747" end_char="753">gabatar</TOKEN>
<TOKEN id="token-11-6" pos="word" morph="none" start_char="755" end_char="756">da</TOKEN>
<TOKEN id="token-11-7" pos="word" morph="none" start_char="758" end_char="763">kasida</TOKEN>
<TOKEN id="token-11-8" pos="word" morph="none" start_char="765" end_char="767">mai</TOKEN>
<TOKEN id="token-11-9" pos="word" morph="none" start_char="769" end_char="773">taken</TOKEN>
<TOKEN id="token-11-10" pos="punct" morph="none" start_char="775" end_char="775">"</TOKEN>
<TOKEN id="token-11-11" pos="word" morph="none" start_char="776" end_char="780">Arewa</TOKEN>
<TOKEN id="token-11-12" pos="word" morph="none" start_char="782" end_char="784">ina</TOKEN>
<TOKEN id="token-11-13" pos="word" morph="none" start_char="786" end_char="789">muka</TOKEN>
<TOKEN id="token-11-14" pos="word" morph="none" start_char="791" end_char="794">dosa</TOKEN>
<TOKEN id="token-11-15" pos="punct" morph="none" start_char="795" end_char="795">"</TOKEN>
<TOKEN id="token-11-16" pos="word" morph="none" start_char="797" end_char="800">Tace</TOKEN>
<TOKEN id="token-11-17" pos="word" morph="none" start_char="802" end_char="809">yakamata</TOKEN>
<TOKEN id="token-11-18" pos="word" morph="none" start_char="811" end_char="814">Ê¼yan</TOKEN>
<TOKEN id="token-11-19" pos="word" morph="none" start_char="816" end_char="820">arewa</TOKEN>
<TOKEN id="token-11-20" pos="word" morph="none" start_char="822" end_char="823">su</TOKEN>
<TOKEN id="token-11-21" pos="word" morph="none" start_char="825" end_char="828">hada</TOKEN>
<TOKEN id="token-11-22" pos="word" morph="none" start_char="830" end_char="834">kansu</TOKEN>
<TOKEN id="token-11-23" pos="word" morph="none" start_char="836" end_char="837">su</TOKEN>
<TOKEN id="token-11-24" pos="word" morph="none" start_char="839" end_char="842">kuma</TOKEN>
<TOKEN id="token-11-25" pos="word" morph="none" start_char="844" end_char="846">san</TOKEN>
<TOKEN id="token-11-26" pos="word" morph="none" start_char="848" end_char="851">inda</TOKEN>
<TOKEN id="token-11-27" pos="word" morph="none" start_char="853" end_char="856">suka</TOKEN>
<TOKEN id="token-11-28" pos="word" morph="none" start_char="858" end_char="861">fito</TOKEN>
<TOKEN id="token-11-29" pos="word" morph="none" start_char="863" end_char="864">da</TOKEN>
<TOKEN id="token-11-30" pos="word" morph="none" start_char="866" end_char="869">kuma</TOKEN>
<TOKEN id="token-11-31" pos="word" morph="none" start_char="871" end_char="874">inda</TOKEN>
<TOKEN id="token-11-32" pos="word" morph="none" start_char="876" end_char="879">suka</TOKEN>
<TOKEN id="token-11-33" pos="word" morph="none" start_char="881" end_char="884">nufa</TOKEN>
<TOKEN id="token-11-34" pos="punct" morph="none" start_char="885" end_char="885">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
