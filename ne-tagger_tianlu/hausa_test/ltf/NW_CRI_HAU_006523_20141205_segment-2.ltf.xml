<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_CRI_HAU_006523_20141205_segment-2">
    <TEXT><SEG id="segment-2" start_char="342" end_char="451">
<ORIGINAL_TEXT>Ta kuma bayyana cewa, kasar Sin za ta hada kai da kasar Kenya don ganin an gudanar da bincike yadda ya kamata.</ORIGINAL_TEXT>
<TOKEN id="token-2-0" pos="word" morph="none" start_char="342" end_char="343">Ta</TOKEN>
<TOKEN id="token-2-1" pos="word" morph="none" start_char="345" end_char="348">kuma</TOKEN>
<TOKEN id="token-2-2" pos="word" morph="none" start_char="350" end_char="356">bayyana</TOKEN>
<TOKEN id="token-2-3" pos="word" morph="none" start_char="358" end_char="361">cewa</TOKEN>
<TOKEN id="token-2-4" pos="punct" morph="none" start_char="362" end_char="362">,</TOKEN>
<TOKEN id="token-2-5" pos="word" morph="none" start_char="364" end_char="368">kasar</TOKEN>
<TOKEN id="token-2-6" pos="word" morph="none" start_char="370" end_char="372">Sin</TOKEN>
<TOKEN id="token-2-7" pos="word" morph="none" start_char="374" end_char="375">za</TOKEN>
<TOKEN id="token-2-8" pos="word" morph="none" start_char="377" end_char="378">ta</TOKEN>
<TOKEN id="token-2-9" pos="word" morph="none" start_char="380" end_char="383">hada</TOKEN>
<TOKEN id="token-2-10" pos="word" morph="none" start_char="385" end_char="387">kai</TOKEN>
<TOKEN id="token-2-11" pos="word" morph="none" start_char="389" end_char="390">da</TOKEN>
<TOKEN id="token-2-12" pos="word" morph="none" start_char="392" end_char="396">kasar</TOKEN>
<TOKEN id="token-2-13" pos="word" morph="none" start_char="398" end_char="402">Kenya</TOKEN>
<TOKEN id="token-2-14" pos="word" morph="none" start_char="404" end_char="406">don</TOKEN>
<TOKEN id="token-2-15" pos="word" morph="none" start_char="408" end_char="412">ganin</TOKEN>
<TOKEN id="token-2-16" pos="word" morph="none" start_char="414" end_char="415">an</TOKEN>
<TOKEN id="token-2-17" pos="word" morph="none" start_char="417" end_char="423">gudanar</TOKEN>
<TOKEN id="token-2-18" pos="word" morph="none" start_char="425" end_char="426">da</TOKEN>
<TOKEN id="token-2-19" pos="word" morph="none" start_char="428" end_char="434">bincike</TOKEN>
<TOKEN id="token-2-20" pos="word" morph="none" start_char="436" end_char="440">yadda</TOKEN>
<TOKEN id="token-2-21" pos="word" morph="none" start_char="442" end_char="443">ya</TOKEN>
<TOKEN id="token-2-22" pos="word" morph="none" start_char="445" end_char="450">kamata</TOKEN>
<TOKEN id="token-2-23" pos="punct" morph="none" start_char="451" end_char="451">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
