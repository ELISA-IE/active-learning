<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE LCTL_TEXT SYSTEM "ltf.v1.5.dtd">
<LCTL_TEXT>
  <DOC id="NW_VOA_HAU_004523_20140401_segment-0">
    <TEXT><SEG id="segment-0" start_char="0" end_char="342">
<ORIGINAL_TEXT>WASHINGTON D.C.— A daidai lokacin da kungiyar kare hakin bil adama ta Amnesty International ta fito da rahoton dake cewa an aikata laifin yaki a arewa maso gabashin Najeriya sai gashi dattawan jihohin Borno da Yobe da Adamawa dake zaune a Abuja sun yi korafin cewa gwamnatin tarayya ta gaza wurin dakatarda kashe-kashen dake faruwa a yankinsu.</ORIGINAL_TEXT>
<TOKEN id="token-0-0" pos="word" morph="none" start_char="0" end_char="9">WASHINGTON</TOKEN>
<TOKEN id="token-0-1" pos="word" morph="none" start_char="11" end_char="11">D</TOKEN>
<TOKEN id="token-0-2" pos="punct" morph="none" start_char="12" end_char="12">.</TOKEN>
<TOKEN id="token-0-3" pos="word" morph="none" start_char="13" end_char="13">C</TOKEN>
<TOKEN id="token-0-4" pos="punct" morph="none" start_char="14" end_char="15">.—</TOKEN>
<TOKEN id="token-0-5" pos="word" morph="none" start_char="17" end_char="17">A</TOKEN>
<TOKEN id="token-0-6" pos="word" morph="none" start_char="19" end_char="24">daidai</TOKEN>
<TOKEN id="token-0-7" pos="word" morph="none" start_char="26" end_char="32">lokacin</TOKEN>
<TOKEN id="token-0-8" pos="word" morph="none" start_char="34" end_char="35">da</TOKEN>
<TOKEN id="token-0-9" pos="word" morph="none" start_char="37" end_char="44">kungiyar</TOKEN>
<TOKEN id="token-0-10" pos="word" morph="none" start_char="46" end_char="49">kare</TOKEN>
<TOKEN id="token-0-11" pos="word" morph="none" start_char="51" end_char="55">hakin</TOKEN>
<TOKEN id="token-0-12" pos="word" morph="none" start_char="57" end_char="59">bil</TOKEN>
<TOKEN id="token-0-13" pos="word" morph="none" start_char="61" end_char="65">adama</TOKEN>
<TOKEN id="token-0-14" pos="word" morph="none" start_char="67" end_char="68">ta</TOKEN>
<TOKEN id="token-0-15" pos="word" morph="none" start_char="70" end_char="76">Amnesty</TOKEN>
<TOKEN id="token-0-16" pos="word" morph="none" start_char="78" end_char="90">International</TOKEN>
<TOKEN id="token-0-17" pos="word" morph="none" start_char="92" end_char="93">ta</TOKEN>
<TOKEN id="token-0-18" pos="word" morph="none" start_char="95" end_char="98">fito</TOKEN>
<TOKEN id="token-0-19" pos="word" morph="none" start_char="100" end_char="101">da</TOKEN>
<TOKEN id="token-0-20" pos="word" morph="none" start_char="103" end_char="109">rahoton</TOKEN>
<TOKEN id="token-0-21" pos="word" morph="none" start_char="111" end_char="114">dake</TOKEN>
<TOKEN id="token-0-22" pos="word" morph="none" start_char="116" end_char="119">cewa</TOKEN>
<TOKEN id="token-0-23" pos="word" morph="none" start_char="121" end_char="122">an</TOKEN>
<TOKEN id="token-0-24" pos="word" morph="none" start_char="124" end_char="129">aikata</TOKEN>
<TOKEN id="token-0-25" pos="word" morph="none" start_char="131" end_char="136">laifin</TOKEN>
<TOKEN id="token-0-26" pos="word" morph="none" start_char="138" end_char="141">yaki</TOKEN>
<TOKEN id="token-0-27" pos="word" morph="none" start_char="143" end_char="143">a</TOKEN>
<TOKEN id="token-0-28" pos="word" morph="none" start_char="145" end_char="149">arewa</TOKEN>
<TOKEN id="token-0-29" pos="word" morph="none" start_char="151" end_char="154">maso</TOKEN>
<TOKEN id="token-0-30" pos="word" morph="none" start_char="156" end_char="163">gabashin</TOKEN>
<TOKEN id="token-0-31" pos="word" morph="none" start_char="165" end_char="172">Najeriya</TOKEN>
<TOKEN id="token-0-32" pos="word" morph="none" start_char="174" end_char="176">sai</TOKEN>
<TOKEN id="token-0-33" pos="word" morph="none" start_char="178" end_char="182">gashi</TOKEN>
<TOKEN id="token-0-34" pos="word" morph="none" start_char="184" end_char="191">dattawan</TOKEN>
<TOKEN id="token-0-35" pos="word" morph="none" start_char="193" end_char="199">jihohin</TOKEN>
<TOKEN id="token-0-36" pos="word" morph="none" start_char="201" end_char="205">Borno</TOKEN>
<TOKEN id="token-0-37" pos="word" morph="none" start_char="207" end_char="208">da</TOKEN>
<TOKEN id="token-0-38" pos="word" morph="none" start_char="210" end_char="213">Yobe</TOKEN>
<TOKEN id="token-0-39" pos="word" morph="none" start_char="215" end_char="216">da</TOKEN>
<TOKEN id="token-0-40" pos="word" morph="none" start_char="218" end_char="224">Adamawa</TOKEN>
<TOKEN id="token-0-41" pos="word" morph="none" start_char="226" end_char="229">dake</TOKEN>
<TOKEN id="token-0-42" pos="word" morph="none" start_char="231" end_char="235">zaune</TOKEN>
<TOKEN id="token-0-43" pos="word" morph="none" start_char="237" end_char="237">a</TOKEN>
<TOKEN id="token-0-44" pos="word" morph="none" start_char="239" end_char="243">Abuja</TOKEN>
<TOKEN id="token-0-45" pos="word" morph="none" start_char="245" end_char="247">sun</TOKEN>
<TOKEN id="token-0-46" pos="word" morph="none" start_char="249" end_char="250">yi</TOKEN>
<TOKEN id="token-0-47" pos="word" morph="none" start_char="252" end_char="258">korafin</TOKEN>
<TOKEN id="token-0-48" pos="word" morph="none" start_char="260" end_char="263">cewa</TOKEN>
<TOKEN id="token-0-49" pos="word" morph="none" start_char="265" end_char="273">gwamnatin</TOKEN>
<TOKEN id="token-0-50" pos="word" morph="none" start_char="275" end_char="281">tarayya</TOKEN>
<TOKEN id="token-0-51" pos="word" morph="none" start_char="283" end_char="284">ta</TOKEN>
<TOKEN id="token-0-52" pos="word" morph="none" start_char="286" end_char="289">gaza</TOKEN>
<TOKEN id="token-0-53" pos="word" morph="none" start_char="291" end_char="295">wurin</TOKEN>
<TOKEN id="token-0-54" pos="word" morph="none" start_char="297" end_char="305">dakatarda</TOKEN>
<TOKEN id="token-0-55" pos="word" morph="none" start_char="307" end_char="311">kashe</TOKEN>
<TOKEN id="token-0-56" pos="punct" morph="none" start_char="312" end_char="312">-</TOKEN>
<TOKEN id="token-0-57" pos="word" morph="none" start_char="313" end_char="318">kashen</TOKEN>
<TOKEN id="token-0-58" pos="word" morph="none" start_char="320" end_char="323">dake</TOKEN>
<TOKEN id="token-0-59" pos="word" morph="none" start_char="325" end_char="330">faruwa</TOKEN>
<TOKEN id="token-0-60" pos="word" morph="none" start_char="332" end_char="332">a</TOKEN>
<TOKEN id="token-0-61" pos="word" morph="none" start_char="334" end_char="341">yankinsu</TOKEN>
<TOKEN id="token-0-62" pos="punct" morph="none" start_char="342" end_char="342">.</TOKEN>
</SEG>
</TEXT>
  </DOC>
</LCTL_TEXT>
